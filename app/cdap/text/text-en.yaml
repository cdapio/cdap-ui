---
# Please keep this file alphabetically sorted!
commons:
  application: Application
  apply: Apply
  as: as
  back: Back
  cask: CASK
  cdap: CDAP
  clickhere: click here
  close: Close
  delete: Delete
  deprecated: Deprecated
  descriptionLabel: Description
  doneLabel: Done
  duplicate: Duplicate
  DSVEditor:
    placeholder: value
  dataset: Dataset
  edit: Edit
  entity:
    application:
      plural: Applications
      short-singular: App
      short-plural: Apps
      singular: Application
    artifact:
      plural: Artifacts
      singular: Artifact
      extensions: Extensions
      applications: Applications
      type: Type
    cdap-data-pipeline:
      plural: Data Pipelines
      singular: Data Pipeline
    cdap-data-streams:
      plural: Data Streams
      singular: Data Stream
    dataset:
      plural: Datasets
      singular: Dataset
      programs: Programs
      operations: Operations
      writes: Writes
    flow:
      plural: Flows
      singular: Flow
    metrics:
      programs: Programs
      running: Running
      failed: Failed
    mapreduce:
      plural: MapReduce
      singular: MapReduce
    program:
      plural: Programs
      singular: Program
      status: Status
      runs: Runs
      application: Application
    service:
      plural: Services
      singular: Service
    spark:
      plural: Spark
      singular: Spark
    worker:
      plural: Workers
      singular: Worker
    workflow:
      plural: Workflows
      singular: Workflow
  export: Export
  formatLabel: Format
  hydrator: Cask Hydrator
  keyValPairs:
    keyLabel: Key
    keyPlaceholder: key
    valueLabel: Value
    valuePlaceholder: value
  market: Hub
  milliSecondsShortLabel: ms
  nameLabel: Name
  noLabel: No
  notAvailable: 'N/A'
  please: Please
  pipelines: Pipelines
  resource-center: Add entity
  schemaLabel: Schema
  scope: Scope
  secondsShortLabel: secs
  secShortLabel: sec
  status: Status
  then: Then
  tracker: Cask Tracker
  typeLabel: Type
  when: When
  wrangler: Cask Wrangler
  yesLabel: Yes
features:
  AboutPage:
    copyright:
      firstLine: Copyright Â© 2014-2017 Cask Data, Inc.
      secondLine:
        view: "View "
        termsAndConditions: Terms and Conditions
        and: " and "
        privacyPolicy: Privacy Policy
    mode: "Mode: "
    providers:
      aws: Amazon Web Services (AWS)
      azure: Microsoft Azure
      forLabel: for
      gcp: Google Cloud Platform (GCP)
    security: "Security: "
    version: Version {version}
  AbstractWidget:
    DLPWidget:
      apply: Apply
      on: on
      within: within
    PluginListWidget:
      emptyLabel: "No {pluginType} plugins"
    SecureKeyTextarea:
      customEntryHelper: Specify a different secure key
      customEntryPlaceholder: Type the name of secure key
      title: Select from the list or specify a different secure key
    SqlSelectorWidget:
      collapseAll: Collapse All
      expandAll: Expand All
      resetAll: Reset All
      table:
        aliasHeader: Alias
        checkboxHeader: Select
        selectMenuItems:
          all: All
          none: None
        stageNameHeader: Name
  AccessTokenModal:
    accessToken: "Access token: "
    close: Close
    login:
      textContent: Please enter your username and password to generate a new access token
      usernamePlaceholder: Username
      passwordPlaceholder: Password
      submit: Generate access token
      error: Login failed. Please check your username and password and try again.
    modalHeader: Access token
  Administration:
    Accordions:
      Namespace:
        create: Create New Namespace
        customApps: Custom apps
        description: Create, view, and manage namespaces
        label: "Namespaces "
        labelWithCount: "Namespaces ({count})"
        noNamespace: No namespace available
      SystemPrefs:
        create: Edit System Preferences
        description: Manage system preferences available as runtime arguments to programs across all namespaces
        label: "System Preferences "
        labelWithCount: "System Preferences ({count})"
        noPrefs: No system preferences set
      SystemProfiles:
        create: Create New Profile
        description: Manage compute profiles available to launch programs in all namespaces
        label: "System Compute Profiles "
        labelWithCount: "System Compute Profiles ({count})"
        import: Import
    Configure:
      title: Configure
      buttons:
        MakeRESTCalls:
          label: Make HTTP Calls
        ReloadSystemArtifacts:
          confirmationButton: "Reload"
          confirmationHeader: Reload system artifacts
          confirmationText: "Are you sure you want to reload all system artifacts?"
          errorMessage: Failed to load system artifacts
          label: Reload System Artifacts
      pageTitle: '{productName} | Administration | Configuration'
    Management:
      pageTitle: '{productName} | Administration | Management'
    Tethering:
      TetheringStatus:
        accepted: Accepted
        rejected: Rejected
        pending: Pending
      TetheringRequests:
        tetheringRequestHeader: Tethering requests
        tetheringRequestHistory: VIEW REQUEST HISTORY
        noTetheringRequests: There are no tethering requests
        acceptButton: Accept
        rejectButton: Reject
        acceptSuccess: Request has been accepted.
      Connections:
        connectionsHeader: Connections
        noConnections: There are no connections
        allocation: Allocation
      NewRequests:
        newRequestsHeader: New requests
        noNewRequests: There are no new requests
      CreateRequest:
        createRequestButton: CREATE NEW REQUEST
        headerTitle: Create new tethering request
        backButton: Back
        sendButton: Send Request
        cancelButton: Cancel
        success: Your request was created successfully
        failure: Failed to create request
        inputValidationError: Required field {fieldName} has no value
        nsValidationError: At least one namespace must be selected
        TetheredNamespaces:
          title: Tethered Namespaces
          description: Select the namespaces that will be tethered to the cloud instance
          noNamespaces: There are no available namespaces
          Name:
            name: namespace
            label: Name
          CpuLimit:
            name: cpuLimit
            label: CPU (# of cores)
          MemoryLimit:
            name: memoryLimit
            label: Memory (GB)
        CDFInformation:
          title: CDF Information
          ProjectName:
            name: projectName
            label: Project Name
            placeholder: Specify the Google Cloud project name
          Region:
            name: region
            label: Region
            placeholder: Specify the region
          InstanceName:
            name: instanceName
            label: Instance Name
            placeholder: Specify the Cloud Data Fusion instance name
          InstanceUrl:
            name: instanceUrl
            label: Instance Url
            placeholder: Specify the Cloud Data Fusion instance url
          Description:
            name: description
            label: Description
            placeholder: Describe the rationale for the tethering request
      ColumnHeaders:
         tetheringStatus: Tethering Status
         requestTime: Request Time
         description: Description
         gcp: Google cloud project
         instanceName: Instance name
         instanceUrl: Instance URL
         region: Region
         tetheredNamespace: Tethered namespace
         cpu: CPU (# of cores)
         memory: Memory (GB)
      Actions:
        edit: Edit
        delete: Delete
      ConfirmationModal:
        deleteRequestHeader: Delete Tethering Request
        deleteRequestCopy: Are you sure you want to delete this request?
        deleteConnectionHeader: Delete Tethering Connection
        deleteConnectionCopy: Are you sure you want to delete this connection?
        rejectRequestHeader: Reject Tethering Request
        rejectRequestCopy: Are you sure you want to reject this request?
      pageTitle: '{productName} | Administration | Tethering Connections'
    Services:
      title: Services
      headers:
        name: Name
        provisioned: Provisioned
        requested: Requested
        status: Status
      appfabric: App Fabric
      dataset_executor: Dataset Executor
      explore_service: Explore Service
      log_saver: Log Saver
      messaging_service: Messaging Service
      metrics: Metrics
      metrics_processor: Metrics Processor
      metadata_service: Metadata Service
      remote_system_operation: Remote System Operation
      requested: Requested
      setBtn: Set
      runtime: Runtime
      transaction: Transaction
      viewlogs: View Logs
    systemMetrics: System metrics
    Tabs:
      config: Configuration
      management: Management
      tethering: Tethering Connections
    Top:
      primaryLabelOne: DAY
      primaryLabelTwo: HR
      primaryLabelThree: MIN
      services: Services
      time-label: Uptime
      updated: Last updated
      updated-label:
        plural: seconds ago
        singular: second ago
      version-label: Version
    Title: Administration
    uptimeLabel: Uptime {time}
  AppDetailedView:
    Tabs:
      datasetsLabel: Datasets
  AuthorizationMessage:
    callToAction1: Please contact your system administrator to request access to a namespace
    callToAction2:
      message1: You are logged in as *{username}*.
      loginLabel: " Login "
      message2: as another user
    callToAction3:
      message1: "Create a new namespace "
      message2: "(Note: You will require ADMIN privileges for creating a namespace)"
    mainMessage: " You are not authorized to access any existing namespace"
  Cloud:
    Profiles:
      common:
        deleteConfirmation: Are you sure you want to delete the profile *_{profile}_*?
        deleteError: There was a problem deleting the profile
        deleteTitle: Delete profile
        disabledDeleteProfile: Profile needs to be disabled to delete
        disabled: Disabled
        enabled: Enabled
        export: Export
        last24HrNodeHr: Last 24 hrs node hours
        last24HrRuns: Last 24 hrs runs
        provisioner: Provisioner
        totalNodeHr: Total node hours
        totalRuns: Total runs
        totalWorkerCores: Total cores
        autoScaleBadge: Auto
        autoScaleTooltip: Autoscaling of worker nodes is enabled.
      CreateView:
        ProvisionerSelection:
          pageTitle: '{productName} | Profiles | Create'
        pageTitle: '{productName} | Profiles | Create | {provisioner_name}'
        profileName: Profile name
        profileNamePlaceholder: Name for compute profile
        profileLabel: Profile label
        profileLabelPlaceholder: Label the compute profile
      DetailView:
        Associations:
          Header:
            created: Created
            label: Pipelines currently using {profile}
            last24hrsnodehr: Last 24 hrs node hours
            last24hrsruns: Last 24 hrs runs
            name: Name
            namespace: Namespace
            noAssociations: No pipelines currently using this profile
            schedules: Schedules
            totalnodehr: Total node hours
            totalruns: Total runs
            triggers: Triggers
        computeProfileOverview: Compute profile overview
        creation: Created
        disableConfirmation: Are you sure you want to disable the profile *_{profile}_*? Any programs or pipelines using this profile will fail to start.
        disableError: There was a problem disabling the profile
        disableTitle: Disable profile
        disableYes: Disable
        enableError: "There was a problem enabling the profile: {message}"
        hideDetails: Hide Details
        noProperties: No properties available for this profile
        pageTitle: '{productName} | Profiles | {profile_name}'
        profileDetails: Profile details
        profileUsage: "{profile} usage"
        secureKeyPopover: Service account is stored using a secure key
        viewDetails: View Details
      ListView:
        assosciations: Assosciations
        createOne: "creating one"
        default: Default
        importError: Unable to import profile
        noProfiles: "No compute profiles have been defined in this namespace. Start by "
        noProfilesSystem: "No compute profiles have been defined in the system. Start by "
        pipelineUsage: Pipeline usage
        profileName: Profile name
        profileUsage: Profile usage
        schedules: Schedules
        triggers: Triggers
  ConfirmationModal:
    cancelDefaultText: Cancel
    confirmDefaultText: OK
  CopyableID:
    label: RunID
    copiedLabel: Copied
    notAvailable: ID Not Available
  EntityListView:
    Cards:
      type: "Type: "
    emptyMessage:
      clearText:
        add: Add
        browse: Browse
        clear: Clear
        entities: " new entities; or"
        filter: " your filters; or"
        Market: " Hub"
        search: " your search; or"
      default: No entities found in namespace "{namespace}"
      filter: No entities found for your selection
      search: No results found for "{searchText}"
      suggestion: "You can try to:"
    Errors:
      retryNow: Retry now
      retrying: Retrying...
      secondsLabel: seconds.
      tryAgain: Unable to communicate with system services. Retrying in
      timeOut: Timed out while attempting to communicate with system services. Please contact your system administrator.
    Header:
      filterBy: Filter by
      search-placeholder: Search
      sort: Sort
      sortLabel: "Sort by "
      sortOptions:
        creationTimeDesc:
          displayName: Newest
        creationTimeAsc:
          displayName: Oldest
        entityNameAsc:
          displayName: A - Z
        entityNameDesc:
          displayName: Z - A
        none: ''
    Info:
      entities: entities
      subtitle:
        displayAll: Displaying all entities
        displaySome: Displaying
        filteredBy: filtered by
        search: Search results for
        sortedBy: sorted by
      title: Entities in namespace "{namespace}"
    JustAddedSection:
      subtitle: Just added
    NamespaceNotFound:
      createMessage: Create a
      createLinkLabel: new namespace
      optionsSubtitle: Here are some options on what to do next
      switchMessage: Select a different namespace from the namespace dropdown
    PageErrorMessage:
      errorMessage: Page {pageNum} not found
      suggestionMessage1: "Go back to:"
      suggestionMessage2: Page 1
    Title: '{productName} | {featureName}'
  DataPrepServiceControl:
    btnLabel: "Enable {featureName}"
    btnLoadingLabel: "Enabling..."
    description: "{featureName} provides an easy and interactive way to visualize, transform, and cleanse data. It allows the user to view data from a local source, a cluster or a database, and derive new schemas and operationalize the data preparation with a few clicks."
    list:
      1: Easy and interactive way to work with messy data
      2: Apply transformations using a variety of operations on various data types
      3: Quickly visualize results of transformations, and patterns both within and across columns
      4: Operationalize effortlessly into production pipeline
    title: "Welcome to {featureName}"
  DataPrep:
    DataPrepSidePanel:
      columnsTabLabel: Columns ({columnsCount})
      ColumnsTab:
        EmptyMessage:
          clearLabel: Clear
          suggestionTitle: "You can try to:"
          suggestion1: your search
          title: No match found for {searchText}
        ColumnDetail:
          Header:
            inferredType: Inferred type
            percentageChange: "% Chance"
        Header:
          completion: Completion
          name: Name
        searchPlaceholder: Search
        toggle:
          clearAll: Clear All
          selectAll: Select All
      directivesTabLabel: Transformation steps ({directivesCount})
      targetTabLabel: Target
      TargetTab:
        selectDataModel: "Select a target data model to start mapping"
        targetDataModel: "Target data model"
      DirectivesTab:
        label: Transformations
      noColumns: No columns
      noDirectives: No transformations
    DataPrepTable:
      DataType:
        unknown: unknown
      copyToNewColumn:
        inputDuplicate: A column with the same name already exists. Pick a new name, or click "Ok" to cancel.
        inputLabel: Name new column
        inputPlaceholder: Destination column
        inputSuffix: _copy
        label: Copy to a new column
      dataErrorMessageTitle: Unable to load data.
      dataErrorMessageTitle2: Unable to load data for "{workspaceName}".
      emptyWorkspace: No data
      invalidCharacterWarning: The name you have entered is invalid. It must contain only letters, numbers, and underscores (_). Pick a new name, or click "Ok" to cancel.
      noData: No data. Try removing some transformation steps.
    DataPrepBrowser:
      BigQueryBrowser:
        datasetCount:
          0: No datasets
          1: "{context} dataset"
          _: "{context} datasets"
        datasets: Datasets
        EmptyMessage:
          emptyDatasetList: 'No datasets in connection _{connectionName}_'
          emptyTableList: 'No tables in dataset _{datasetName}_'
        name: Name
        pageTitle: '{productName} | Connections | Google BigQuery | {connectionId}'
        title: Select table
      DatabaseBrowser:
        defaultErrorMessage: Reading {tableId} failed. Please try again.
        EmptyMessage:
          clearLabel: Clear
          emptyDatabase: 'No tables in connection _{connectionName}_'
          suggestionTitle: "You can try to:"
          suggestion1: your search
          title: 'No match found for "{searchText}"'
        pageTitle: '{productName} | Connections | Database | {connectionId}'
        searchPlaceholder: Search table name
        table:
          namecollabel: NAME
        tableCount:
          0: No tables
          1: '{context} table'
          _: "{context} tables"
        title: Select table
      GCSBrowser:
        BrowserData:
          Content:
            directory: Directory
            emptyBucket: No files or directories found in this bucket
            EmptymessageContainer:
              suggestion1: your search
          Headers:
            LastModified: Last modified
            Name: Name
            Size: Size
            Type: Type
        pageTitle: '{productName} | Connections | Google Cloud Storage | {connectionId}'
        Search:
          placeholder: Search this directory
        TopPanel:
          ListingInfo:
            label: "{dirsCount} directories and {filesCount} files"
            truncatedContentsTooltip: The GCS account you are viewing contains more directories and files we can currently display.
            truncatedLabel: "{dirsCount} directories and {fileCount} files of many"
          selectData: Select data
      GenericBrowser:
        EmptyMessageContainer:
          title: No entities found
          suggestion1: your search
          suggestion2: Browse to another location
          suggestion3: Choose a different connection
          suggestion4: Choose a connection from left panel
        EntityCount:
          bucket:
            1: 1 bucket
            _: "{context} buckets"
          database:
            1: 1 database
            _: "{context} databases"
          dataset:
            1: 1 dataset
            _: "{context} datasets"
          directory:
            1: 1 directory
            _: "{context} directories"
          file:
            1: 1 file
            _: "{context} files"
          instance:
            1: 1 instance
            _: "{context} instances"
          schema:
            1: 1 schema
            _: "{context} schemas"
          table:
            1: 1 table
            _: "{context} tables"
          topic:
            1: 1 topic
            _: "{context} topics"
          generic: "{type}: {count}"
          empty: No results
          filtered: "{countString} shown of {total} total"
      KafkaBrowser:
        EmptyMessage:
          clearLabel: Clear
          emptyKafka: 'No topics in connection _{connectionName}_'
          suggestionTitle: "You can try to:"
          suggestion1: your search
          title: 'No match found for "{searchText}"'
        pageTitle: '{productName} | Connections | Kafka | {connectionId}'
        searchPlaceholder: Search topic
        table:
          topics: Topics
        topicCount:
          0: No topics
          1: '{count} topic'
          _: "{count} topics"
        title: Select topic
      noDataMsg: No data
      S3Browser:
        BucketData:
          Content:
            emptyBucket: No files or directories found in this bucket
            EmptymessageContainer:
              suggestion1: your search
          Headers:
            LastModified: Last modified
            Name: Name
            Owner: Owner
            Size: Size
        pageTitle: '{productName} | Connections | S3 | {connectionId}'
        Search:
          placeholder: Search this directory
        TopPanel:
          ListingInfo:
            label: "{dirsCount} directories and {filesCount} files"
            truncatedContentsTooltip: The bucket you are viewing contains more directories and files we can currently display.
            truncatedLabel: "{dirsCount} directories and {fileCount} files of many"
          selectData: Select data
      SpannerBrowser:
        databaseCount:
          0: No databases
          1: "{context} database"
          _: "{context} databases"
        databases: Databases
        EmptyMessage:
          emptyDatabaseList: 'No databases in instance _{instanceName}_ of connection _{connectionName}_'
          emptyInstanceList: 'No instances in connection _{connectionName}_'
          emptyTableList: 'No tables in database _{databaseName}_ of instance _{instanceName}_ of connection _{connectionName}_'
        instanceCount:
          0: No instances
          1: "{context} instance"
          _: "{context} instances"
        instances: Instances
        name: Name
        pageTitle: CDAP | Connections | Google Cloud Spanner | {connectionId}
        tableCount:
          0: No tables
          1: "{context} table"
          _: "{context} tables"
        title: Select data
      ADLSBrowser:
        EmptyMessage:
          emptyDatasetList: 'No Data'
          emptyTableList: 'No Data'
        name: Name
        pageTitle: '{productName} | Connections | ADLS | {connectionId}'
        title: 'ADLS'
        Search:
          placeholder: Search this directory
        TopPanel:
          ListingInfo:
            label: "{dirsCount} directories and {filesCount} files"
          selectData: Select data
    Directives:
      accept: Ok
      apply: Apply
      cancel: Cancel
      Calculate:
        columnTypeLabel:
          numeric: Numeric
        destinationColumnInputLabel: Name destination column
        disabledTooltip: "Calculate can only be applied on columns of data type 'string', 'integer', 'short', 'long', 'float', 'double', 'decimal'"
        newColumnInputCountSuffix: _count
        Options:
          POWEROF:
            description: "Raise the column value to the power of:"
        OptionsLabels:
          ABSVALUE: Absolute value
          ADD: Add
          ARCCOS: Arccos
          ARCSIN: Arcsin
          ARCTAN: Arctan
          CEIL: Ceil
          CHARCOUNT: Character count
          COS: Cos
          CUBE: Cube
          CUBEROOT: Cube root
          DIVIDE: Divide
          FLOOR: Floor
          LOG: Log
          MODULO: Modulo
          MULTIPLY: Multiply
          NATURALLOG: Natural log
          POWEROF: Power of
          RANDOM: Random
          ROUND: Round
          SIN: Sin
          SQUARE: Square
          SQUAREROOT: Square root
          SUBTRACT: Subtract
          TAN: Tan
          DECIMALADD: Add
          DECIMALSUBTRACT: Subtract
          DECIMALMULTIPLY: Multiply
          DECIMALDIVIDEQ: Divide
          DECIMALDIVIDER: Modulo
          DECIMALABSVALUE: Absolute value
          DECIMALPOWEROF: Power of
          DECIMALSQUARE: Square
          DECIMALCUBE: Cube
          PRECISION: Precision
          SCALE: Scale
          UNSCALED: Unscaled
          DECIMALLEFT: Decimal left
          DECIMALRIGHT: Decimal right
          NEGATE: Negate
          STRIPZERO: Strip trailing zeros
          SIGN: Sign
          CROSSADD: Add
          CROSSSUBTRACT: Subtract
          CROSSMULTIPLY: Multiply
          CROSSDIVIDEQ: Divide
          CROSSDIVIDER: Modulo
          CROSSLCM: LCM
          CROSSEQUAL: Equal
          CROSSMAX: Max
          CROSSMIN: Min
          CROSSAVG: Average
          MULTIADD: Add
          MULTIMULTIPLY: Multiply
          MULTIEQUAL: Equal
          MULTIMAX: Max
          MULTIMIN: Min
          MULTIAVG: Average
        title: Calculate
      ChangeDataType:
        disabledTooltip: "Change data type is not available on columns of data type 'LocalDate', 'LocalTime', or 'ZonedDateTime'"
        Options:
          boolean: Boolean
          bytes: Bytes
          double: Double
          float: Float
          integer: Integer
          long: Long
          short: Short
          string: String
          decimal: Decimal
        title: Change data type
      ColumnActions:
        label: Column names
        actions:
          bulkset: Set all
          cleanse: Cleanse
          replaceColumns: Replace
        Bulkset:
          description: Enter column names in order starting from the first column
          modalTitle: Bulk set column names
          setBtnLabel: Set Columns
          textareaplaceholder: "Enter column names separated by commas. Special characters (eg., @ - #) are not allowed"
        ReplaceColumns:
          applyButton: Replace
          ignoreCase: Ignore case
          modalTitle: Replace column names
          PatternInputPlaceholder:
            PREFIX: "e.g. body_, work_"
          patternLabel: Pattern
          PatternTypeLabel:
            CUSTOM: Replace pattern
            PATTERN: Remove pattern
            PREFIX: Remove prefix
          replaceLabel: Replace
          replaceWithPlaceholder: Leave empty to remove pattern, else add a replacement pattern
          withLabel: With
      Copy:
        title: Copy column
      CustomTransform:
        description: 'Type the custom expression to transform "{column}"'
        placeholder: "E.g. math:sin({column}), empty(arg), {column}+<column>, etc."
        title: Custom transform
      CutDirective:
        cancelBtnLabel: Exit 'Extract' mode
        extractDescription: Extract characters *_{range}_* from this column to a new column
        inputLabel: Name of destination column
        popoverTitle: Extract using position
      CutMenuItem:
        menuLabel: Using positions
      Decode:
        base32: Base32
        base64: Base64
        hex: Hex
        title: Decode
        urldecode: URL
      DefineVariable:
        Conditions:
          CUSTOMCONDITION: Custom condition
          TEXTCONTAINS: value contains
          TEXTENDSWITH: value ends with
          TEXTEXACTLY: value is
          TEXTREGEX: value matches regex
          TEXTSTARTSWITH: value starts with
        if: Select row where
        Placeholders:
          CUSTOMCONDITION: Enter custom condition
          TEXTCONTAINS: Enter contained value
          TEXTENDSWITH: Enter suffix
          TEXTEXACTLY: Enter value
          TEXTREGEX: Enter regex
          TEXTSTARTSWITH: Enter prefix
        step1: "Set variable name"
        step2: "Choose variable value"
        selectColumnLabel: Select column in selected row
        summaryLabel: "Summary:"
        summaryText: "you defined the variable \"{variableName}\" for the cell in column {selectedColumn} in the row which {condition} _{value}_ in column \"{columnName}\""
        title: Define variable
        variableNamePlaceholder: Enter variable_name
      Drop:
        title:
          plural: Delete selected columns
          singular: Delete column
      Encode:
        base32: Base32
        base64: Base64
        hex: Hex
        title: Encode
        url: URL
      Explode:
        title: Explode
        filtersSubmenuTitle: Delimited text
        flatteningSubmenuTitle: Array (by flattening)
        recordFlatteningSubmenuTitle: Record (by flattening)
      ExtractFields:
        delimitersSubmenuTitle: Using delimiters
        extractBtnLabel: Extract
        patternSubmenuTitle: Using patterns
        positionsSubmenuTitle: Using positions
        title: Extract fields
        UsingPatterns:
          creditCardPattern: Credit cards
          creditCardPatternExample: '#### #### #### ####'
          customPattern: Custom
          customPatternContent:
            description: Write your own regex pattern
          datePattern: Date
          datetimePattern: Date time
          disabledTooltip: Extracting fields using patterns can only be applied on columns of data type 'string'
          emailPattern: Email
          exampleLabel: 'E.g.'
          htmlHyperlinkPattern: URLs from HTML anchors
          hidePatternLabel: Hide pattern
          isbncodePattern: ISBN codes
          ipv4Pattern: IPv4 address
          macaddressPattern: Mac addresses
          modalTitle: Extract fields using patterns
          ndigitnumberPattern: N digits number
          ndigitnumberPatternContent:
            description1: Extract numbers with
            description2: digits
          patternDescription: Select a pattern to extract from the column "{column}"
          phoneNumberPattern: U.S. phone numbers
          phoneNumberPatternExample: 'e.g. (###) - ###-####'
          selectPatternMessage: Select a pattern
          showPatternLabel: Show Pattern
          ssnPattern: SSN
          ssnPatternExample: '###-##-####'
          startEndPattern: Start/End pattern
          startEndPatternContent:
            description1: Extract text that start with
            description2: and end with
          timePattern: Time
          upscodePattern: UPS codes
          urlPattern: URL
          zipCodePattern: US zip codes
        UsingDelimiters:
          comma: Comma
          custom: Custom separator
          modalTitle: Extract fields using delimiter
          pipe: Pipe
          tab: Tab
          whitespace: Whitespace
      failedApplyDirectiveMessage: Failed to apply. Please modify input and try again #temporary fallback until backend sends non-null error
      FillNullOrEmpty:
        title: Fill null or empty cells
      Filter:
        Conditions:
          CUSTOMCONDITION: Custom condition
          EMPTY: value is empty
          TEXTCONTAINS: value contains
          TEXTENDSWITH: value ends with
          TEXTEXACTLY: value is
          TEXTREGEX: value matches regex
          TEXTSTARTSWITH: value starts with
        customconditiontooltiptitle: JEXL expressions
        customconditiontooltip: "A custom condition can be defined using JEXL expressions. For more details regarding JEXL, please refer to  "
        customconditiontooltiplink: JEXL Expressions
        if: If
        ignoreCase: Ignore case
        KEEP: Keep rows
        Placeholders:
          CUSTOMCONDITION: "E.g. < 30 || gender == \"Male\""
          TEXTCONTAINS: Enter contained value
          TEXTENDSWITH: Enter suffix
          TEXTEXACTLY: Enter value
          TEXTREGEX: Enter regex
          TEXTSTARTSWITH: Enter prefix
        REMOVE: Remove rows
        title: Filter
      FindAndReplace:
        buttonLabel: Replace All
        exactMatchLabel: Exact match
        find: Find
        findPlaceholder: Old value
        ignoreCaseLabel: Ignore case
        replacePlaceholder: New value
        replaceWith: Replace with
        title: Find and replace
      Format:
        disabledTooltip: "Format can only be executed on columns of data type 'string', 'date', or 'datetime'"
        Formats:
          CONCATENATE:
            addDescription: of the content of each row
            addLabel: Add
            addOptions:
              BEGINNING: at the beginning
              END: at the end
            inputPlaceholder: Enter string
            label: Concatenate
          DATE_TIME:
            label: Date and time
          DATETIME_AS_STRING:
            label: Datetime
          LOWERCASE:
            label: lowercase
          TITLECASE:
            label: TitleCase
          TRIM_LEADING_WHITESPACE:
            label: Trim leading whitespace
          TRIM_TRAILING_WHITESPACE:
            label: Trim trailing whitespace
          TRIM_WHITESPACE:
            label: Trim whitespace
          UPPERCASE:
            label: UPPERCASE
        title: Format
      Hash:
        BLAKE2B-160: BLAKE2B-160
        BLAKE2B-256: BLAKE2B-256
        BLAKE2B-384: BLAKE2B-384
        BLAKE2B-512: BLAKE2B-512
        encode: Encode
        GOST3411: GOST3411
        GOST3411-2012-256: GOST3411-2012-256
        GOST3411-2012-512: GOST3411-2012-512
        KECCAK-224: KECCAK-224
        KECCAK-256: KECCAK-256
        KECCAK-288: KECCAK-288
        KECCAK-384: KECCAK-384
        KECCAK-512: KECCAK-512
        MD2: MD2
        MD4: MD4
        MD5: MD5
        RIPEMD128: RIPEMD128
        RIPEMD160: RIPEMD160
        RIPEMD256: RIPEMD256
        RIPEMD320: RIPEMD320
        SHA: SHA
        SHA-1: SHA-1
        SHA-224: SHA-224
        SHA-256: SHA-256
        SHA-384: SHA-384
        SHA-512: SHA-512
        SHA-512/224: SHA-512/224
        SHA-512/256: SHA-512/256
        SHA3-224: SHA3-224
        SHA3-256: SHA3-256
        SHA3-384: SHA3-384
        SHA3-512: SHA3-512
        Skein-1024-1024: Skein-1024-1024
        Skein-1024-384: Skein-1024-384
        Skein-1024-512: Skein-1024-512
        Skein-256-128: Skein-256-128
        Skein-256-160: Skein-256-160
        Skein-256-224: Skein-256-224
        Skein-256-256: Skein-256-256
        Skein-512-128: Skein-512-128
        Skein-512-160: Skein-512-160
        Skein-512-224: Skein-512-224
        Skein-512-256: Skein-512-256
        Skein-512-384: Skein-512-384
        Skein-512-512: Skein-512-512
        SM3: SM3
        Tiger: Tiger
        title: Hash
        WHIRLPOOL: WHIRLPOOL
      Keep:
       title:
          plural: Keep selected columns
          singular: Keep column
      MarkAsError:
        Conditions:
          CUSTOMCONDITION: Custom condition
          EMPTY: value is empty
          ISAMEXCARD: value is American Express card
          ISBOOLEAN: value is boolean
          ISCOUNTRYTLD: value is country TLD
          ISCREDITCARD: value is credit card
          ISDATE: value is date
          ISDATEFORMAT: value is date format
          ISDINERCARD: value is Diner card
          ISDOMAINNAME: value is domain name
          ISDOMAINTLD: value is domain TLD
          ISDOUBLE: value is double
          ISEMAIL: value is email
          ISGENERICTLD: value is generic TLD
          ISINTEGER: value is integer
          ISIP: value is IP
          ISIPV4: value is IPV4
          ISIPV6: value is IPV6
          ISISBN10: value is ISBN10
          ISISBN13: value is ISBN13
          ISISBN: value is ISBN
          ISMASTERCARD: value is Master card
          ISNOTAMEXCARD: value is not American Express card
          ISNOTBOOLEAN: value is not boolean
          ISNOTCOUNTRYTLD: value is not country TLD
          ISNOTCREDITCARD: value is not credit card
          ISNOTDATE: value is not date
          ISNOTDATEFORMAT: value is not date format
          ISNOTDINERCARD: value is not Diner card
          ISNOTDOMAINNAME: value is not domain name
          ISNOTDOMAINTLD: value is not domain TLD
          ISNOTDOUBLE: value is not double
          ISNOTEMAIL: value is not email
          ISNOTGENERICTLD: value is not generic TLD
          ISNOTINTEGER: value is not integer
          ISNOTIP: value is not IP
          ISNOTIPV4: value is not IPV4
          ISNOTIPV6: value is not IPV6
          ISNOTISBN10: value is not ISBN10
          ISNOTISBN13: value is not ISBN13
          ISNOTISBN: value is not ISBN
          ISNOTMASTERCARD: value is not Master card
          ISNOTNUMBER: value is not number
          ISNOTTIME: value is not time
          ISNOTURL: value is not URL
          ISNOTVISACARD: value is not Visa card
          ISNOTVPAYCARD: value is not VPay card
          ISNUMBER: value is number
          ISTIME: value is time
          ISURL: value is URL
          ISVISACARD: value is Visa card
          ISVPAYCARD: value is VPay card
          TEXTCONTAINS: value contains
          TEXTENDSWITH: value ends with
          TEXTEXACTLY: value is
          TEXTREGEX: value matches regex
          TEXTSTARTSWITH: value starts with
        ignoreCase: Ignore case
        if: If
        Placeholders:
          CUSTOMCONDITION: "E.g. {column} < 30 || gender == \"Male\""
          TEXTCONTAINS: Enter contained value
          TEXTENDSWITH: Enter suffix
          TEXTEXACTLY: Enter value
          TEXTREGEX: Enter regex
          TEXTSTARTSWITH: Enter prefix
          ISDATEFORMAT: "Eg: MM/DD/YYYY"
          ISNOTDATEFORMAT: "Eg: MM/DD/YYYY"
        title: Send to error
        tooltip: When used in a pipeline, these errors can be collected by an error collector
      MaskData:
        menuLabel: Mask data
        option1: Show last 4 characters only
        option2: Show last 2 characters only
        option3: Custom selection
        option4: By shuffling
      MaskSelection:
        cancelBtnLabel: Exit 'Mask Data' mode
        description: Mask the selected characters across all rows in this column
        popoverTitle: Mask
      Merge:
        buttonLabel: Join
        chooseDelimiter: Choose delimiter
        customDelimiterPlaceholder: e.g. $
        Delimiters:
          COLON: Colon
          COMMA: Comma
          CUSTOMDELIMITER: Custom delimiter
          DASH: Dash
          PERIOD: Period
          PIPE: Pipe
          SPACE: Space
          UNDERSCORE: Underscore
        duplicate: A column with the same name already exists. Pick a new name, or click âJoinâ to overwrite.
        newColumn: Name new column
        newColumnPlaceholder: Destination column
        setOrder: Set order
        title: Join two columns
      Parse:
        modalTitle: Parse as {parser}
        Parsers:
          AVRO:
            label: Avro
          CSV:
            customPlaceholder: "Delimiter (e.g ;, #, %, ^)"
            deprecatedWarning: "Deprecated"
            firstRowHeader: Set first row as header
            label: CSV
            modalTitle: Please select the delimiter
            Options:
              COMMA: Comma
              CONTROL_A: ^A
              CONTROL_D: ^D
              CUSTOM: Custom delimiter
              PIPE: Pipe
              SPACE: Space
              TAB: Tab
          EXCEL:
            label: Excel
            modal:
              description: Choose how you would like to specify the sheet in your Excel file
              firstRowHeader: Set first row as header
              sheetNameInputPlaceholder: Sheet name
              sheetNameLabel: Sheet name
              sheetNumberLabel: Sheet number
          FIXEDLENGTH:
            fieldLabel: Column widths
            label: Fixed length
            optionalFieldLabel: Padding
            optionalPlaceholder: Optional padding parameter
            placeholder: "e.g. 3, 5, 2, 5, 15"
          HL7:
            label: HL7
          JSON:
            fieldLabel: Depth
            label: JSON
            placeholder: Enter depth
          LOG:
            customPlaceholder: "e.g. %h %l %u %t \"%r\" %>s %b"
            label: Log
            modalTitle: Please select the logs format
            Options:
              AGENT: Agent
              CUSTOM: Custom
              COMMON: Common
              COMBINED: Combined
              COMBINEDIO: Combinedio
              REFERER: Referer
          NATURALDATE:
            fieldLabel: Timezone
            label: Natural date
            placeholder: "e.g. UTC"
          SIMPLEDATE:
            customPlaceholder: "e.g. yyyy.MM.dd G 'at' HH:mm:ss z"
            label: Simple date
            ModalHeader:
              parse: Parse as {parser}
              format: Format date and time
            modalTitle: Please select the date format
            Options:
              CUSTOM: Custom format
              OPTION1: "MM/dd/yyyy"
              OPTION2: "dd/MM/yyyy"
              OPTION3: "MM-dd-yyyy"
              OPTION4: "MM-dd-yy"
              OPTION5: "yyyy-MM-dd"
              OPTION6: "yyyy-MM-dd HH:mm:ss"
              OPTION7: "MM-dd-yyyy 'at' HH:mm:ss with timezone"
              OPTION8: "dd/MM/yy HH:mm:ss"
              OPTION9: "yyyy,MM.dd'T'HH:mm:ss.SSS with RFC timezone"
              OPTION10: "MM.dd.yyyy HH:mm:ss.SSS"
              OPTION11: "EEE, d MMM yyyy HH:mm:ss"
              OPTION12: "EEE, MMM d, 'yy"
              OPTION13: "h:mm AM/PM"
              OPTION14: "H:mm with timezone"
          DATETIME:
            customPlaceholder: "e.g. yyyy.MM.dd G 'at' HH:mm:ss z"
            label: Datetime
          XMLTOJSON:
            fieldLabel: Depth
            label: XML to JSON
            placeholder: Enter depth
        title: Parse
      SetCharEncoding:
        disabledTooltip: Character encoding can only be set on columns of data type 'bytes'
        iso88591: ISO-8859-1
        title: Set character encoding
        usascii: US-ASCII
        utf16: UTF-16
        utf16be: UTF-16BE
        utf16le: UTF-16LE
        utf8: UTF-8
      SetCounter:
        Conditions:
          ALWAYS: Always
          IFCONDITION: If condition is true
        ifConditionPlaceholder: Enter JEXL condition
        incrementCounterLabel: increment the count by
        title: Set counter
        variableNameLabel: Name this counter
        variableNamePlaceholder: Enter counter name
      Swap:
        title: Swap two column names
      MapToTarget:
        title: Map to Target
        initializingText: Initializing...
        loadingText: Loading...
        executingDirectiveText: Executing directive...
        CurrentSelection:
          emptySelection: Select Data Model
          dataModelLabel: Data Model
          modelLabel: Table
        OptionFilter:
          modelPlaceholder: Type to filter table
          fieldPlaceholder: Type to filter field
    pageTitle: '{productName} | {featureName} {workspaceUri}'
    PipelineError:
      bigquery: Unable to find Google BigQuery plugin. Please install Google Cloud Plugins from Hub.
      database: Unable to find Database Plugins. Please make sure Database Plugins are available.
      defaultMessage: Error adding to pipeline.
      fileBatch: Unable to find Core Plugins. Please make sure Core Plugins are available.
      fileRealtime: Unable to find Spark Plugins. Please make sure Spark Plugins are available.
      gcs: Unable find Google Cloud Storage plugin. Please install Google Cloud Plugins from Hub.
      kafka: Unable to find Kafka Plugins. Please install Kafka Plugins from Hub.
      s3: Unable find S3 plugin. Please install Amazon S3 Plugins from Hub.
      spanner: Unable find Google Cloud Spanner plugin. Please install Google Cloud Plugins from Hub.
      adls: Unable find ADLS Handler plugin. Please make sure ADLS Plugins are available.
      missingWranglerPlugin: Cannot find wrangler-transform plugin. Please load wrangler transform from Hub
    sidePanelTooltip:
      collapse: Collapse the side panel
      expand: Expand the side panel
    TopPanel:
      addToPipelineBtnLabel: Create a Pipeline
      addToPipelineModal:
        title: Choose the type of pipeline to create
        batchPipelineBtn: Batch pipeline
        realtimePipelineBtn: Realtime pipeline
        errorTitle: Unable to create pipeline
      applyBtnLabel: Apply
      bigquery: Google BigQuery
      cleanseLinkLabel: "cleanse "
      copyToCDAPDatasetBtn:
        btnLabel: Ingest Data
        copyingSteps:
          Step1: 'Preparing to copy...'
          Step1Error: 'Unable to copy data.'
          Step2: 'Submitting copy task...'
          Step2Error: 'Unable to submit copy task.'
        createBtnLabel: Ingest Data
        description: You are creating a new dataset, select a type and enter information about this new entity
        disabledTooltip: The Ingest Data option is unavailable for uploaded files.
        Form:
          datasetNameLabel: Dataset name
          datasetTooltip: Name of the dataset to copy to
          fileSetBtnlabel: Fileset
          formatLabel: Format
          formatTooltip: Format of data
          requiredLabel: Required
          rowKeyLabel: Row key
          rowKeyTooltip: The name of the record field that should be used as the row key when writing to the table.
          typeLabel: Type
          tableBtnlabel: Table
        Formats:
          avro: Avro
          orc: ORC
          parquet: Parquet
        modalTitle: Ingest data
        monitorBtnLabel: Explore data
        ingestFailMessage: Unable to ingest data
        uploadDisabledMessage: Ingesting data from a locally uploaded file is not supported.
      database: Database
      databaseTitle: "Table: {name}"
      file: File System
      gcs: Google Cloud Storage
      adls: ADLS File System
      invalidFieldNameMessage: Invalid column name "{fieldName}"
      invalidFieldNameRemedies1: "Spaces and special characters other than - or _ are not allowed in column names."
      invalidFieldNameRemedies2: "You can try to "
      invalidFieldNameRemedies3: column names.
      kafka: Kafka
      more: More
      columns: Columns
      rows: Rows
      PlusButton:
        addDirective: Add directive
        successMessage: You successfully added a custom directive. Apply that directive by typing it into the power mode input area.
      realtimeDisabledTooltip: "Importing data from {type} in realtime is currently not supported."
      s3: S3
      spanner: Google Cloud Spanner
      SchemaModal:
        defaultErrorMessage: Error generating schema.
      Tabs:
        dataprep: Data
        dataviz: Insights
      title: Data Preparation
      upgradeBtnLabel: Upgrade
      UpgradeModal:
        confirmation: Are you sure you want to upgrade Data Preparation?
        modalHeader: Upgrade Data Preparation
      upload: Local File Upload
      viewSchemaBtnLabel: View Schema
    Upgrade:
      errorCommunicating: Error while communicating with {featureName} service
      errorTitle: Enabling {featureName} failed
      failedToStop: Failed to stop {featureName} service
      minimumVersionError: "{featureName} requires wrangler-service artifact version {minimumVersion} or above. Version {highestVersion} found. Please install the latest wrangler-service from Hub."
    WorkspaceTabs:
      DeleteModal:
        cancelButton: No, keep tab open
        confirmButton: Yes, close tab
        header: Close tab
        helperMessage: Any transformation steps you have applied in this tab will be lost.
        mainMessage: Are you sure you want to close {workspace}?
  DataPrepConnections:
    AddConnections:
      BigQuery:
        bucket: Temporary Google Cloud Storage bucket
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        defaultTestErrorMessage: Cannot connect to Google BigQuery
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        ModalHeader:
          ADD: "Add connection: Google BigQuery"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          bucket: Specify a GCS bucket used to store temporary data
          name: Specify a name to identify this connection
          projectId: Specify your GCP project ID
          serviceAccountKeyfile: Specify the location of the file containing your GCP service account
        projectId: Project ID
        serviceAccountKeyfile: Service account key file location
        testConnection: Test Connection
      Database:
        DatabaseDetail:
          advanced: Advanced
          backButton: View All Drivers
          basic: Basic
          Buttons:
            ADD: Add Connection
            DUPLICATE: Duplicate Connection
            EDIT: Save Changes
          connectionString: Connection string
          connType: JDBC connections
          customLabel: "Other..."
          database: Database
          defaultTestErrorMessage: Error connecting to database
          driverInstalled: Driver installed
          ErrorMessages:
            ADD: Failed to add connection
            DUPLICATE: Failed to duplicate connection
            EDIT: Failed to edit connection
          hostname: Host
          name: Connection name
          password: Password
          Placeholders:
            connectionString: "{connectionString}"
            connectionStringDefault: Specify database connection string
            name: Specify a name to identify this connection

          port: Port
          required: Required
          testConnection: Test Connection
          username: Username
        DatabaseOptions:
          install: "Install driver: "
          installedLabel: Driver installed
          market: Hub
          optionsTitle: Select the type of database you want to connect to
          upload: Upload
        ModalHeader:
          ADD: "Add connection: Database"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
      GCS:
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        defaultTestErrorMessage: Cannot connect to Google Cloud Service
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        ModalHeader:
          ADD: "Add connection: Google Cloud Storage"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          name: Specify a name to identify this connection
          projectId: Specify your GCP project ID
          serviceAccountKeyfile: Specify the location of the file containing your GCP service account

        projectId: Project ID
        required: Required
        serviceAccountKeyfile: Service account key file location
        testConnection: Test Connection
      Kafka:
        brokersList: Broker host
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        connectionType: Connection type
        defaultTestErrorMessage: Cannot connect to Kafka
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        kafka: Kafka
        ModalHeader:
          ADD: "Add connection: Kafka"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          name: Specify a name to identify this connection
        port: Port
        required: Required
        testConnection: Test Connection
        zkQuorum: Zookeeper host
        zookeeper: Zookeeper
      label: Add Connection
      Popover:
        title: Select a source to connect
      S3:
        accessKeyId: Access key ID
        accessSecretKey: Secret access key
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        defaultTestErrorMessage: Cannot connect to S3
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        ModalHeader:
          ADD: "Add connection: S3"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          accessKeyId: Specify your AWS access key ID
          accessSecretKey: Specify your AWS secret access key
          name: Specify a name to identify this connection
        region: Region
        required: Required
        testConnection: Test Connection
      Spanner:
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        defaultTestErrorMessage: Cannot connect to Google Cloud Spanner
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        ModalHeader:
          ADD: "Add connection: Google Cloud Spanner"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          name: Specify a name to identify this connection
          projectId: Specify your GCP project ID
          serviceAccountKeyfile: Specify the location of the file containing your GCP service account
        projectId: Project ID
        serviceAccountKeyfile: Service account key file location
        testConnection: Test Connection
      ADLS:
        accountFQDN: Account FQDN
        Buttons:
          ADD: Add Connection
          DUPLICATE: Duplicate Connection
          EDIT: Save Changes
        clientID: Client ID
        clientSecret: Client Key
        defaultTestErrorMessage: Cannot connect to ADLS Handler
        ErrorMessages:
          ADD: Failed to add connection
          DUPLICATE: Failed to duplicate connection
          EDIT: Failed to edit connection
        ModalHeader:
          ADD: "Add connection: ADLS Handler"
          DUPLICATE: "Duplicate connection: {connection}"
          EDIT: "Edit connection: {connection}"
        name: Connection name
        Placeholders:
          accountFQDN: Specify Account FQDN
          clientID: Specify Client ID
          clientSecret: Specify Client Key
          name: Specify a name to identify this connection
          refreshURL: Specify End Point Refresh URL
        refreshURL: End Point Refresh URL
        testConnection: Test Connection
      TestConnectionLabels:
        danger: Test connection failed
        success: Test connection successful
      ConnectionList:
        Columns:
          name: Name
          description: Description
          artifact: Artifact
          version: Version
          scope: Scope
        searchPlaceholder: Search connection type
        searchLabel: Search
        showOlderVersions: Show older versions
        hideOlderVersions: Hide older versions
    bigquery: Google BigQuery ({count})

    ConnectionManagement:
      Confirmations:
        DatabaseDelete:
          cancel: Cancel
          deleteButton: Delete Connection
          header: "Delete connection: {connection}"
          helper1: You will no longer able to access data from this source.
          helper2: "You can reconnect to this source at any time by clicking \"Add Connection\""
          mainMessage: "Are you sure you want to delete connection {connection}?"
        failedDeleteMessage: Deleting connection failed
      delete: Delete
      duplicate: Duplicate
      edit: Edit
      editConnection: 'Edit {connector} connection - "{connectionName}"'
      createConnection: "Create a {connector} connection"
      viewConnection: 'View {connector} connection - "{connectionName}"'
      SourceParsing:
        ImportSchema:
          description: In most cases, schema is inferred automatically. Use the Import Schema button to override the inferred schema. It is also useful for specifying schema manually, for formats such as JSON where schema inference is not possible.
    database: Database ({count})
    gcs: Google Cloud Storage ({count})
    hdfs: File System
    kafka: Kafka ({count})
    NoDefaultConnection:
      title: No default connection available
    pageTitle: '{productName} | Connections'
    s3: S3 ({count})
    spanner: Google Cloud Spanner ({count})
    adls: "ADLS Handler ({count})"
    title: "Connections in \"{namespace}\""
    upload: Upload
    UploadComponent:
      fileSizeError: "The file you are trying to upload is larger than 10MB. Please select a smaller file and try again."
      helperText: "Max file size: 10MB"
      recordDelimiter: Record delimiter
      title: Upload data from your computer
      uploadButton: Upload

  DatasetDetailedView:
    Tabs:
      lineage: Lineage
      programsWithCount: Programs ({count})
      properties: Properties
      schema: Schema
    Title: '{productName} | Dataset | {datasetId}'
  Dashboard:
    Title: Dashboard
  Description:
    label: Description
    nodescription: No description available
  DetailView:
    PropertiesTab:
      title: Properties for {entityType} "{entityId}"
  EmptyMessageContainer:
    clearLabel: Clear
    title: 'No match found for "{searchText}"'
    suggestionTitle: "You can try to:"

  Experiments:
    CreateView:
      addModel: Add Model
      algorithmType: "Algorithm type: {type}"
      configureHyperparamsFor: Configure hyperparameters for {algorithm}
      createExperiment: Create Experiment
      createNewExperiment: Create a new experiment
      descriptionPlaceholder: Add a description for this experiment
      experimentName: Experiment name
      experimentNamePlaceholder: Add a name for this experiment
      failedToSplit: "Failed to split data for the experiment '{experimentId}' - Please check "
      logs: "logs "
      MLAlgorithm: "ML algorithm: "
      modelDescription: Model description
      modelDescriptionWithColon: "Model description: "
      modelName: Model name
      modelNameWithColon: "Model name:"
      moreInfo: for more info
      nextSelect: Next, select a machine learning algorithm
      numDirectives: "No of transformation steps: "
      pageTitle: '{productName} | {featureName} | {experimentIdWithSuffix}'
      random: Random
      selectMLAlgorithm: Select a machine learning algorithm
      selectOutcome: Select an outcome
      setOutcome: Set outcome for this experiment
      resplitAndVerify : Resplit data
      splitAndVerify: Split data and verify sample
      splitData: Split data
      SplitInfo:
        categorical: Categorical data
        columnName: Column name
        count: Count
        dataType: "Data type: "
        max: Max
        mean: Mean
        min: Min
        missing: Missing
        numerical: Numerical data
        searchColumn: Search column name
        stddev: Std dev
        unique: Unique
        zero: Zero
      splitMethod: "Split method: "
      splitting: Splitting data
      trainModel: Train Model
      verifySample: Verify sample by feature or outcome
    DetailedView:
      algorithm: Algorithm
      algoTypes: Algorithm types
      copyToClipboard: Copy to Clipboard
      data: Data
      evariance: Evariance
      f1: F1
      mae: Mean absolute error
      modelDescription: Model description
      modelName: Model name
      models:
        1: "{context} model"
        _: "{context} models"
      modelStatus: Model status
      modelTrainingLogs: Model training logs
      numModels: No of models
      outcome: Outcome
      pageTitle: '{productName} | {featureName} | {experiment_name}'
      precision: Precision
      r2: R2
      recall: Recall
      rmse: RMSE
      status: Status
    ListView:
      algoTypes: Algorithm types
      createNew: Create a new experiment
      data: Data
      experiment: Experiment
      experiments:
        1: "{context} experiment"
        _: "{context} experiments"
      numModels: No of models
      pageTitle: '{productName} | {featureName} | All Experiments'
    pageTitle: '{productName} | {featureName}'
    ServiceControl:
      Benefits:
        b1: Intuitive Web UI for building, training, testing and evaluating machine learning models.
        b2: Seamless, integrated experience from data preparation and cleansing to model building and deployment.
        b3: Horizontal scalability over your Big Data environment.
        b4: Out of the box support for common machine learning libraries like SparkML.
        b5: Support for tuning custom hyperparameters for algorithms.
        b6: Integrated metrics and visualization providing rich summaries and graphs for model evaluation.
        title: "Some key benefits of {featureName} are:"
      description: "Data scientists typically build custom tooling for managing their machine learning models and deploying them. {featureName} provides a seamless, automated interface to help users develop, train, test, evaluate and deploy their machine learning models."
      enableBtnLabel: Enable {featureName}
      environmentCheckMessage: Checking for environment before enabling {featureName}
      errorCommunicating: Error while communicating with {featureName} service
      errorTitle: Enabling {featureName} failed
      errorMessage: Please check logs for more information
      serviceDisabledMessage: Please upgrade to Spark 2.0 or later to use {featureName}
      title: Welcome to {featureName}

  FieldLevelLineage:
    Error:
      lineageTooLarge: Field level lineage data is too large to display
      suggestionHeading: "You can try to:"
      suggestionMessage: Change the time range
    fieldsCount:
      1: "{context} Field"
      _: "{context} Fields"
    Headers:
      datasetName: Dataset name
      fieldName: Field name
    incomingOperations: Incoming operations
    noFields: "Field level lineage is not available for the dataset '{datasetId}' in the selected time interval"
    noLineage: No field level lineage available for this field
    noSearchFields: No fields matching the search query
    OperationsModal:
      lastExecution: "Last executed by '{app}' on {time}"
      summaryText: "Transformations between {sources} and {targets}"
      Table:
        description: Description
        input: Input
        inputFields: Input fields
        operation: Transformation
        outputFields: Output fields
        output: Output
        pluginName: Plugin name
      Title:
        incoming: "Cause for field '{fieldName}'"
        outgoing: "Impact for field '{fieldName}'"
    outgoingOperations: Outgoing operations
    searchPlaceholder: Search by field name
    SectionTitle:
      incoming: Cause for
      outgoing: Impact for
      self: Dataset
    Summary:
      datasetCount:
        1: "{context} Dataset"
        _: "{context} Datasets"
      Empty:
        incoming: "There is no cause for __'{fieldId}'__"
        outgoing: "There is no impact for __'{fieldId}'__"
      noFieldSelected: No field selected
      Title:
        incoming: "Cause for:"
        outgoing: "Impact for:"
      viewOperations: View operations
    TimeRangeOptions:
      CUSTOM: Custom
      last14d: Last 14 days
      last6M: Last 6 months
      last7d: Last 7 days
      lastMonth: Last month
      lastYear: Last 12 months
    title: '{productName} | Field Level Lineage | {datasetId}'
    TopPanel:
      subtitle: Explore root cause and impact for each of the fields of the dataset
      timePickerCaption: View field level info in the
      title: Field level lineage
    v2:
      FllHeader:
        InputHeader: "Input datasets to {target}"
        NoRelatedSubheader: "0 datasets"
        OutputHeader: "Output datasets from {target}"
        RelatedSubheader:
          1: "Viewing {first} of {total} dataset"
          _: "Viewing {first} to {last} of {total} datasets"
        TargetHeader: 'Select a field to view lineage and transformations'
        TargetSubheader:
          1:  "Viewing {first} of {total} field"
          _:  "Viewing {first} to {last} of {total} fields"
      FllTable:
        fieldsCount:
          1: "{context} field"
          _: "{context} fields"
        FllExpandableField:
          hideFields: "Hide unrelated fields"
          showFields: "Show unrelated fields"
        FllField:
          viewLineage: "View"
          viewDropdown: "View"
          resetLineage: "Reset"
        FllMenu:
          causeImpact: "Pin field"
          viewIncoming: "View cause"
          viewOutgoing: "View impact"
        FllTableHeader:
          viewLineage: "View lineage"
        noRelatedTables: "There is no {type} for {target}"
        relatedFieldsCount:
          1: "{context} related field"
          _: "{context} related fields"
      TimeRangePicker:
        TimeRangeOptions:
          CUSTOM: Custom
          last14d: Last 14 days
          last6M: Last 6 months
          last7d: Last 7 days
          lastMonth: Last month
          lastYear: Last 12 months
        view: "View"
      TopPanel:
        timePickerCaption: "View"

  ADLSBrowser:
    directory: Directory
    EmptyMessage:
      clearLabel: Clear
      noFilesOrDirectories: No files or directories found in this directory
      suggestion1: your search
      suggestionTitle: "You can try to:"
      title: 'No match found for "{searchText}"'
    Table:
      group: Group
      last-modified: Last modified
      name: Name
      owner: Owner
      permission: Permission
      size: Size
      type: Type
    TopPanel:
      directoryMetrics: "{count} files and directories"
      searchPlaceholder: Search this directory
      selectData: "Select file/directory to preview"

  FileBrowser:
    directory: Directory
    EmptyMessage:
      clearLabel: Clear
      noFilesOrDirectories: No files or directories found in this directory
      suggestion1: your search
      suggestionTitle: "You can try to:"
      title: 'No match found for "{searchText}"'
    Table:
      group: Group
      last-modified: Last modified
      name: Name
      owner: Owner
      permission: Permission
      size: Size
      type: Type
    TopPanel:
      directoryMetrics: "{count} files and directories"
      searchPlaceholder: Search this directory
      selectData: "Select file/directory to preview"

  FileDataUpload:
    click: "Click "
    or: or
    paste: Click anywhere else to paste data
    upload: " to upload a file"

  FileDnD:
    clickLabel: Click to select file from your computer
    uploadLabel: Drag-and-drop the file to be uploaded
  FastAction:
    clearEventsButtonLabel: Clear
    deleteConfirmation: Are you sure you want to delete *_{entityId}_*?
    doneLabel: Done
    Explore:
      actions: Actions
      label: Explore
      noResults: No results
      SQLQuery: SQL query
      startTime: Start time
      status: Status
    deleteLabel: Delete
    downloadDisabledMessage: Results have already been downloaded once. Please run the query to download them again.
    previewDisabledMessage: Results have already been downloaded once. Please run the query to preview them again.
    deleteFailed: Failed to delete {entityId}.
    logLabel: Logs
    logNotAvailable: No logs available
    truncateConfirmation: Are you sure you want to truncate *_{entityId}_*?
    truncateLabel: Truncate
    truncateSuccess: Truncated successfully
    truncateFailed: Failed to truncate {entityId}.
    sendEventsLabel: Send events
    SetPreferences:
      actionLabel: Set preferences
      ButtonLabel:
        saveAndClose: Save & Close
        saving: Saving
      ColumnLabel:
        key: KEY
        value: VALUE
      DescriptionLabel:
        app: Specify new or override existing system or namespace preferences. These preferences will be accessible in all programs within this application.
        namespace: Specify new or override existing system preferences. These preferences will be accessible in all applications within this namespace.
        program: Specify new or override existing system, namespace, or application preferences. These preferences will only be accessible within this program.
        system: Specify new or edit existing system preferences. These preferences will be accessible in all namespaces, applications, and programs.
      failed: Error - Set preferences failed.
      inheritedPrefsLabel: Inherited preferences
      modalLabel: Preferences
      noInheritedPrefs: No inherited preferences
      reset: Reset
      success: "{entityType} preferences saved"
    start: Start
    stop: Stop
    sendEventsButtonLabel: Send
    sendEventsClickLabel: Click to input events.
    sendEventsFailed: Error - Send events failed.
    sendEventsSuccess: Success - Events uploaded successfully.
    startConfirmLabel: Start
    stopConfirmLabel: Stop
    startConfirmation: "Are you sure you want to start the program: *_{entityId}_*?"
    stopConfirmation: "Are you sure you want to stop the program:  *_{entityId}_*?"
    stopProgramHeader: Stop program
    startProgramHeader: Start program
    viewEvents:
      button: View
      failedMessage: Failed to view events
      from: From
      label: View events
      limit: Limit
      modalHeader: "Filter and view events for \"{entityId}\""
      noResults: No results
      numEventsTitle: Set number of events
      timeRangeTitle: Select time range
      to: To

  Home:
    Administration:
      description: Manage system and namespace level settings and preferences.
      namespaceLabel: Namespace
      systemLabel: System
      title: Manage
    Ingestion:
      description: Create and manage simple ingestion from predefined sources.
      linkLabel: Ingest
      title: Ingest
    Metadata:
      description: Discover data using metadata. Perform root cause and impact analysis using lineage.
      linkLabel: Metadata
      title: Discover and govern
    Operations:
      description: Centrally monitor applications for better operations.
      linkLabel: Dashboard
      title: Monitor
    Pipeline:
      description: Ingest and integrate data from on-prem, SaaS, or cloud sources using pipelines.
      listLabel: List
      studioLabel: Studio
      title: Integrate
    Replication:
      description: 'Replicate data changes in real-time from operational databases into analytical databases.'
      linkLabel: 'Replication'
      title: Replicate
    Wrangler:
      description: Explore, transform, cleanse, and enrich data using a code-free environment.
      linkLabel: Wrangler
      title: Wrangle

  HttpExecutor:
    body: Body
    header: Header
    path: Path
    responseTitle: Response
    send: Send
    statusCode: Status Code

  JumpButton:
    buttonLabel: Jump
    viewHydrator: View in Hydrator
    viewTracker: View in Tracker

  licenseText: Licensed under the Apache License, Version 2.0

  LifeCycleManagement:
    discardModalText: An edit draft exists for this pipeline. Click 'Discard' to discard the changes
      that were made and start a new draft. Click 'Continue' to continue editing the existing draft.
    errors:
      noEditChangeError: You have not made any changes to the pipeline, deployment is not allowed.
      outdatedDraftError: A new version of pipeline "{pipelineName}" has been deployed. 
        This draft is outdated and please export the draft for manual reconciliation.

  LoadingIndicator:
    contactadmin: It could take a few minutes for the system to self-heal.
    defaultMessage: 'Loading...'
    nodeserverDown:  UI is experiencing slowness or is unable to communicate with server.
    restartCDAP: Attempting to reconnect, if problem persists refresh the page.
    restartUI: Restart the UI
    servicesDown: Necessary services are experiencing intermittent problems
    serviceDown: The system service {serviceName} is down
    systemDashboard: system services
    tryMessage: 'You can try to: '

  LogViewer:
    noLogsMessage: There are no logs to display

  Market:
    action-types:
      create_app:
        name: Create
      create_pipeline_draft:
        name: Create
      create_pipeline:
        name: Create
      create_artifact:
        name: Create
      create_plugin_artifact:
        name: Deploy
      create_driver_artifact:
        name: Deploy
      deploy_app:
        name: Deploy
      informational:
        name: Download
      load_datapack:
        name: Load
      one_step_deploy_app:
        name: Deploy
      one_step_deploy_plugin:
        name: Deploy
    connectErrorMessage: Cannot connect to Hub
    search-placeholder: Search by name
    tabs:
      all: All
      artifacts: Drivers
      aws: AWS
      azure: Azure
      dashboards: Dashboards
      datapacks: Datapacks
      datasets: Datasets
      directives: Directives
      edwOffload: EDW Offload
      emptyTab: No entities found
      examples: Applications
      gcp: Google Cloud
      pipelines: Pipelines
      plugins: Plugins
      useCases: Solutions
  MarketPlaceEntity:
    closeLabel: Close
    doneLabel: Done
    Metadata:
      author: Author
      company: Company
      created: Created
      licenseInfo: License
      version: Version
    AdditionalCharges:
        description:  This plugin may incur additional charges depending on usage within the pipeline.
        moreInfo: More Info.
  MarketEntityModal:
    version: "Version :"
  NamespaceDetails:
    computeProfiles:
      create: Create New
      description: Select a row to view details about the compute profile
      label: Compute profiles
      labelWithCount: Compute profiles ({count})
      import: Import
    edit: Edit
    entityCounts:
      customApps: Custom apps
    mapping:
      hbaseNamespaceName: 'HBase namespace name: '
      hdfsRootDirectory: 'HDFS root directory: '
      hiveDatabaseName: 'Hive database name: '
      label: Mapping
      schedulerQueueName: 'Scheduler queue name: '
    namespace: Namespace
    namespaceName: Namespace '{namespace}'
    pageTitle: '{productName} | Namespace | {namespace_name}'
    pipelines: Pipelines
    preferences:
      label: Preferences
      labelWithCount: Preferences ({count})
      noPreferences: No preferences set for this namespace
    scope: Scope
    security:
      keytabURI: 'Keytab URI: '
      label: Security
      principal: 'Principal: '
  NamespacesPicker:
    clearAll: Clear All
    monitorNamespace: Monitoring namespace '{namespace}'
    monitorMore: Monitor more
    monitorMultipleNamespaces: Monitoring {count} namespaces {namespaces}
    namespaceName: Namespace name
    namespacesCount:
      1: "{context} namespace"
      _: "{context} namespaces"
    popoverHeader: Select namespaces to monitor
    selectAll: Select All
  Navbar:
    ControlCenter:
      dashboard: Dashboard
      entities: Entities
      label: Control Center
      reports: Reports
    dataprepLabel: Data Preparation
    Dataprep: Preparation
    metadataLabel: Metadata
    MMDS: Analytics
    NamespaceDropdown:
      addNS: "Add Namespace"
      applications: Applications
      datasets: Datasets
      namespaceLabel: Namespace
    pipelinesLabel: Pipelines
    ProductDropdown:
      aboutLabel: About {productName}
      accessToken: Access Token
      dataPrep: Data Preparation
      documentationLabel: Documentation
      logout: Logout
      modes:
        cloudSandbox: Cloud Sandbox
        distributed: Distributed
        localSandbox: Local Sandbox
    rulesmgmt: Rules

  NUX:
    ControlCenter:
      text: "{featureName} allows you to create, manage, operate, and monitor datasets and applications."
    Hub:
      text: "The {featureName} allows administrators to distribute re-usable pipelines, applications, plugins, and solutions to all {productName} users in their organizations."
    Metadata:
      text: "{featureName} enables data discovery through search, and data governance through lineage."
    Pipelines:
      text: "{featureName} is a visual tool to build data pipelines by connecting nodes in a logical flow."
    Preparation:
      text: "{featureName} allows you to easily connect to a variety of data sources and cleanse data using point and click interactions. Once you are satisfied, you can operationalize your transformations in a pipeline."
    Welcome:
      close: No, Thanks
      header: Welcome to {productName}
      showAgainToggle: Don't show tour again.
      startTour: Start Tour
      takeTour: Take a short tour to discover all that you can do.

  Operations:
    pageTitle: '{productName} | {featureName}'

  OpsDashboard:
    header: Dashboard
    pageTitle: '{productName} | {featureName}'
    RunsGraph:
      chart: Chart
      disabledArrowTooltip: The runs timelime is only available for the past 7 days
      header: Runs timeline
      last24Hours: Last 24 hours
      Legends:
        delay: Time delay between starting and running
        failed: Failed runs
        manuallyStarted: Manually started runs
        running: Running
        scheduledTriggered: Scheduled/triggered runs
        successful: Successful runs
        ViewBy:
          label: "View by:"
          runStatus: Run status
          startMethod: Start method
      RunsTable:
        date: Date
        failed: Failed
        manually: Manually
        running: Running
        scheduledTriggered: Scheduled / Triggered
        successful: Successful
        time: Time
        totalRunsEnded: Total runs ended
        totalRunsStarted: Total runs started
        totalStartDelay: Total start delay
      subtitle:
        1: "(across {context} namespace)"
        _: "(across {context} namespaces)"
      table: Table
      TypeSelector:
        customAppsWithCount: Custom apps ({count})
        pipelinesWithCount: Pipelines ({count})
    RunsList:
      duration: Duration
      name: Name
      namespace: Namespace
      noData: No data
      noRuns: No runs in the selected time bucket
      start: Start time
      startMethod: Start method
      status: Status
      timeRange: "{date} from {hour}:00 to {hour}:59 {ampm}"
      title: Selected runs ({count})
      type: Type
      user: User

  Overview:
    DatasetTab:
      title: "Datasets used by \"{appId}\""
    deployedLabel:
      data: Created
      app: Deployed
    errorMessage404: Sorry, we could not find {entityType} "{entityId}"
    errorMessageAuthorization: You are not authorized to view {entityType} "{entityId}"
    errorMessageSubtitle: Select another entity
    Metadata:
      ttl: "Time to live (TTL): "
      type: "Type: "
    overviewCloseLabel: Close
    overviewCloseLabel1: this panel
    ProgramTab:
      altTitle: "Programs using {entityType} \"{entityId}\""
      emptyMessage: No programs found.
      title: "Programs in application \"{appId}\""
      runningProgramLabel: "Number of running programs: {programCount}"
    SchemaTab:
      emptyMessage: No schema found.
      title: Schema of each record in the {entityType} "{entityId}"
      tooltip: Schema defines the structure of each record in the dataset. A schema is a collection of fields, where each field has a name and a data type.
  Page404:
    entityMessage: Sorry, we are not able to find {entityType} "{entityName}"
    genericMessage: Sorry, we are not able to find the page you are looking for.
    homePageLabel: Home Page
    mainTitle: Page not found
    manageLabel: Manage
    overviewLabel: Overview
    pipelinesMessage: Pipelines
    subtitleMessage1: Here are some options on where to go next
    subtitleMessage2: Navigate to
  Page500:
    mainTitle: Unexpected error
    secondaryTitle: We have encountered an error and could not load the page you requested
    suggestion1Part1: Try to
    suggestion1Part2: refresh
    suggestion1Part3: the page
    suggestion2: If you entered the url by hand, double check if that is correct
  MetadataHome:
    pageTitle: "{productName} | Search"
    searchPlaceholder: Search
    searchTipsTitle: Search Tips
    searchTipsSubTitle: Search datasets by
    searchTips1:
      query: The name
      description: "- Input the dataset name by using the format"
      highlight: "entity-name:<dataset-name>"
      example: "(example: entity-name:userprofiles)"
    searchTips2:
      query: A field in the dataset schema
      description: "- Input the field name of a schema using the format"
      highlight: "schema:<field-name>"
      example: "(example: schema:zipcode)"
    searchTips3:
      query: A property annotated on the dataset
      description: "- Input a property as a query, using the format"
      highlight: "<key>:<value>"
      example: "(example: env:production)"
    searchTips4:
      query: A tag annotated on the dataset
      description: "- Input a name of a tag as a query, using the format"
      highlight: "tags:<tag-name>"
      example: "(example: tags:batch)"
    searchTips5:
      query: Wild card
      description: "- Append "
      highlight: "*"
      description1: "to the end of the search term"
      example: "(example: user* or tags:b*)"
  MetadataSearch:
    pageTitle: "{productName} | Search | Results"
    filters:
      metadata: Metadata
      entities: Entities
    searchPlaceholder: Search datasets
    noResults: No results match your filter settings
    loading: "Searching for \"{query}\""
    emptyResults: "No results found for \"{query}\""
    noDescription: No description provided for this Dataset.
    resultCount:
      1: "{page} of {total} result"
      _: "{page} of {total} results"
    created: "Created:"
    filterBy: Filter by
    showAll: show all
    only: only
    sortBy: Sort by
    sortOptions:
      oldest: Oldest First
      newest: Newset First
      ascending: A â Z
      descending: Z â A
  MetadataSummary:
    pageTitle: "{productName} | Search | {entityId} | Results"
    loading: Loading metadata
    businessTags: Business tags
    systemTags: System tags
    enterTagPlaceholder: Enter a tag
    invalidTag: No special characters allowed.
    addTag: Add tag
    duplicateTag: Tag already exists.
    noTags: There are no tags.
    schema: Schema
    noSchema: There is no schema.
    emptySchema: No Schema Available.
    summary: Summary
    lineage: Lineage
    entityTypeTabAriaLabel: Tabs for summary and lineage
    propertiesTabAriaLabel: Tabs for business and system property tags
    noSystemProperties: There are no system properties
    schemaName: Name
    schemaType: Type
    schemaNull: "Null"
    fieldName: Field name
    fieldActions: Actions
    derivedDataset: "The dataset '{derivedDatasetId}' already exists. It's schema cannot be modified."
    inputSchema: This input schema has been derived from the output schema of the previous node(s) and cannot be changed.
    business: Business
    system: System
    deleteProperty: Delete property
    enterPropertyKey: Enter a key
    enterPropertyValue: Enter a value
    propertyKey: Key
    propertyValue: Value
  MetadataLineage:
    pageTitle: "{productName} | Search | {entityId} | Lineage"
    loading: Obtaining lineage information
    dateRange:
      label: Date range
      options:
        custom: Custom
        last7Days: Last 7 days
        last14Days: Last 14 days
        lastMonth: Last month
        last6Months: Last 6 months
        last12Months: Last 12 months
    fieldLevelLineage: Field Level Lineage
    noLineageMsg: No lineage data for the selected time period.
    programRunInfo:
      runId: Run ID
      runs: Runs
      duration: Duration
      started: Started
      status: Status
      close: Close
      loading: Loading
  ApiError:
    CmekError:
      mainTitle: CMEK Key Revoked
      secondaryTitle: Instance is unusable because the CMEK key for this instance has been revoked.
      suggestionPart1: View the
      suggestionPart2: troubleshooting
      suggestionPart3: page
  Pagination:
    dropdown-label: Page

  PipelineConfigurations:
    ActionButtons:
      copyRuntimeArgs: Copy runtime arguments
      runtimeArgsCopied: Runtime arguments copied
      runtimeArgsCount:
        1: "{context} runtime argument"
        _: "{context} runtime arguments"
      save: Save
      saveAndRun: Save & Run
      saveAndSchedule: Save and Schedule
      saving: Saving
      run: Run
    advancedOptions: Advanced options
    Alerts:
      contentHeading: Set alerts for your batch pipeline
      title: Pipeline alert
    Pushdown:
      title: Transformation Pushdown
    ComputeConfig:
      title: Compute config
    EngineConfig:
      backpressure: Backpressure
      backpressureTooltip: Allows the Apache Spark Streaming engine to control the receiving rate based on the current batch scheduling delays and processing times so that the system receives only as fast as the system can process.
      contentHeading: Select the type of engine running your {pipelineTypeLabel} pipeline
      customConfig: Custom config
      customConfigCount:
        1: "{context} custom config"
        _: "{context} custom configs"
      customConfigTooltip: Enter key-value pairs of configuration parameters that will be passed to the underlying {engineDisplayLabel} program.
      dynamicExecution:
        contentHeading: Dynamic Execution
        default: Cluster Default
        forceOff: Force Off
        forceOn: Force On
      mapreduce:
        deprecated: Deprecated
      numExecutors: Number of Executors
      numExecutorsTooltip: The number of executors to allocate for this pipeline on Apache Yarn.
      showCustomConfig: Show custom config
      title: Engine config
    PipelineConfig:
      batchInterval: Batch interval
      checkpointing: Checkpointing
      checkpointingTooltip: Allows Apache Spark Streaming to checkpoint data (RDDs) to persistent storage so that the pipeline can recover from failures.
      checkpointDir: Checkpoint directory
      contentHeading: Set configurations for this pipeline
      instrumentation: Instrumentation
      instrumentationTooltip: Emits timing metrics such as total time, mean, standard deviation for pipeline stages. It is recommended to always have this setting on, unless the environment is short on resources.
      serviceAccountPath: Service Account Path
      serviceAccountPathTooltip: The filepath to the service account credentials to use when connecting to BigQuery.
      stageLogging: Stage level logging
      stageLoggingTooltip: Allows logs from each stage in the pipeline to be queried individually. It is recommended to always have this setting on, unless the environment is short on resources.
      title: Pipeline config
      previewTimeoutTooltip: Number of minutes to run Realtime pipeline preview. It can be run for a maximum of 15 mins
      previewRecordsTooltip: The number of records to be read during the pipeline preview. For MapReduce, this translates to the number of records that are read by each map task
    Resources:
      client: Client
      clientTooltip: Resources for the client process which launches the Apache Spark Streaming pipeline
      driver: Driver
      driverTooltip: Resources for the driver process which initializes the pipeline
      executor: Executor
      executorMapReduce: Mapper/Reducer
      executorTooltip: Resources for executor processes which run tasks in an Apache Spark pipeline
      executorMapReduceTooltip: Resources for the executor process which initializes the pipeline
      contentHeading: Specify the resources for the following processes of the {engineDisplayLabel} program
      title: Resources
    RuntimeConfig:
      title: Runtime arguments
      contentHeading: Specify runtime arguments or update the ones derived from preferences
      contentSubHeading: By default, values for all runtime arguments must be provided before running the pipeline.
          If a stage in your pipeline provides the value of an argument, you can skip that argument
          by marking it as provided.
    PreviewConfig:
      title: Preview config
    title: Configure
    titleHistorical: Run configurations

  PipelineDetails:
    duration: Duration
    PipelineRuntimeArgsDropdownBtn:
      RuntimeArgsTabContent:
        ProvidedPopover:
          clearAll: Clear All
          provided: Provided
          selectAll: Select All
        RuntimeArgsModeless:
          runBtnPopover: Run the pipeline once with the runtime arguments set above. Any changes made to the runtime arguments will be available only for the next run.
          saveBtnPopover: Changes to runtime arguments will be saved for all future runs of the pipeline. This may impact any schedules and triggers configured for this pipeline.
          specifyArgs: Specify runtime arguments, empty values need to come from the pipeline.
          showReservedKeys: Show auto-generated runtime arguments
          tooltipLabel: Key value pairs generated from pipeline configurations that will apply at runtime
          numOfGeneratedRuntimeArgs: 
            1: "{context} auto-generated runtime argument"
            _: "{context} auto-generated runtime arguments"

    ProfilesListView:
      click: Click here
      countProfiles:
        1: '{context} compute profile'
        _: '{context} compute profiles'
      noProfiles: No profiles created
      toCreate: to create one

    RunLevel:
      configs: Runtime Args
      configsModelessTitle: "Runtime arguments for run #{currentRunIndex}"
      copyRuntimeArgsBtnLabel: Copy Runtime Arguments
      currentIndex: '({currentRunIndex} of {numRuns})'
      currentRunIndex: 'Run {currentRunIndex} of {numRuns}'
      errors: Errors
      logs: Logs
      noRuns: No Runs
      noRuntimeArgsForRun: No runtime arguments available for this run.
      pipelineNeverRun: 'This pipeline has never been run.'
      RunComputeProfile:
        label: Compute profile
        noInfo: Profile information unavailable
      runsCurrentlyRunning: Runs currently running - select one to view
      status: Status
      warnings: Warnings
    startTime: Start time
    TopPanel:
      actions: Actions
      configure: Configure
      deleteConfirmation:
        confirm: Delete
        confirmPrompt: 'Are you sure you want to delete the pipeline '
        pipeline: 'Pipeline '
        proceedPrompt: ' is deleted. Are you sure you want to proceed?'
        title: Delete pipeline
        trigger: ' is configured to trigger '
        triggerDelete: '. Triggers will be deleted if pipeline '
        triggerPluralCheck:
          1: "pipeline "
          _: "pipelines "
      deleteError: There was a problem with the pipeline you were trying to delete
      details: Details
      duplicate: Duplicate
      edit: Edit
      export: Export
      exportModalTitle: Export pipeline configuration
      history: History
      run: Run
      schedule: Schedule
      starting: Starting
      stop: Stop
      stopping: Stopping
      StopPopover:
        currentRuns: Current runs ({numRuns})
        stopAll: Stop All
        stopRun: Stop run
      summary: Summary
      unschedule: Unschedule
      version: version {version}

  PipelineList:
    cdap-data-pipeline: Batch
    cdap-data-streams: Realtime
    deployed: Deployed
    DeleteConfirmation:
      confirm: Delete
      confirmDraftPrompt: 'Are you sure you want to delete the draft '
      confirmPrompt: 'Are you sure you want to delete the pipeline '
      deleteError: 'There was a problem with the pipeline you were trying to delete'
      pipeline: 'Pipeline '
      proceedPrompt: ' is deleted. Are you sure you want to proceed?'
      title: Delete pipeline
      titleDraft: Delete draft
      trigger: ' is configured to trigger '
      triggerDelete: '. Triggers will be deleted if pipeline '
      triggerPluralCheck:
        1: "pipeline "
        _: "pipelines "
    DeployedPipelineView:
      graphQLMultipleServicesDown: The system is unable to display the list of pipelines because some of the services are down. Please try again later.
      searchPlaceholder: Search by pipeline name
      pipelineCount:
        1: "{context} pipeline"
        _: "{context} pipelines"
    draft: Drafts
    DraftPipelineView:
      draftCount:
        1: "{context} pipeline you saved"
        _: "{context} pipelines you saved"
    duration: Duration
    editStatus: Status
    EmptyList:
      actionTitle: "You can try to:"
      aPipeline: a pipeline
      create: Create
      EmptySearch:
        actionTitle: "You can try to:"
        clear: Clear
        heading: "There are no pipelines matching the search query \"{search}\""
        search: search query
      import: Import
      Message:
        DRAFT: There are no pipelines you saved as drafts
        DEPLOYED: There are no pipelines deployed
    lastSaved: Last saved
    lastStartTime: Last start time
    name: Pipeline name
    nextRun: Next run in
    runs: Total runs
    selectOne: " - Select one to view"
    status: Status
    tags: Tags
    type: Type

  PipelineResources:
    cpu: CPU
    mb: MB
    memory: Memory

  PipelineScheduler:
    advanced:
      day: Day
      daysOfWeek: Days of the week
      header: Schedule this pipeline by using Cron syntax
      hour: Hour
      label: Advanced
      min: Min
      month: Month
    basic: Basic
    computeProfiles: Compute profiles
    header: Configure schedule for pipeline
    intervalOptions:
      daily: Daily
      every10min: Every 10 min
      every30min: Every 30 min
      every5min: Every 5 min
      heading: Pipeline run repeats
      hourly: Hourly
      monthly: Monthly
      weekly: Weekly
      yearly: Yearly
    maxConcurrentRuns: Max concurrent runs
    repeatEvery:
      day: day(s)
      dayOfMonth: day of the month
      hour: hour(s)
      label: Repeats every
    saveSchedule: Save Schedule
    saveAndStartSchedule: Save and Start Schedule
    selectAProfile: Select a profile
    startingAt:
      label: Starting at
      pastTheHour: past the hour
    startSchedule: Start Schedule
    summary:
      atHourMinuteAMPM: 'at {hour}:{min}{AMPM}.'
      canMaxConcurrentRuns: 'The pipeline can have {num} concurrent runs.'
      cannotMaxConcurrentRuns: 'The pipeline cannot have concurrent runs.'
      every: 'every '
      everyDateOfMonth: 'every {date} day of the month, '
      everyDay: 'everyday, '
      everyHour: 'every hour, '
      everyNumDays: 'every {num} days, '
      everyNumHours: 'every {num} hours, '
      everyYearOn: 'every year on {month} {dateOfMonth}, '
      label: Summary
      numMinsPastTheHour: '{num} minutes past the hour.'
      onTheHour: 'on the hour.'
      scheduledToRun: 'This pipeline is scheduled to run '
    suspendSchedule: Suspend Schedule

  PipelineSummary:
    filterContainer:
      view: View
    graphs:
      emptyMessage: No runs {filter}
      vizSwitcher:
        chart: Chart
        table: Table
    logsMetricsGraph:
      hint:
        errors: Errors
        runNumber: Run number
        startTime: Start time
        title: Log errors & warnings
        viewLogs: View Logs
        warnings: Warnings
      legend1: Warnings
      legend2: Errors
      table:
        body:
          viewLog: View Log
        header:
          errors: Errors
          runCount: Run#
          startTime: Start time
          warnings: Warnings
      title: Log errors and warnings
      xAxisTitle: "Pipeline run #"
      yAxisTitle: Number of errors and warnings
    nodesMetricsGraph:
      hint:
        errors: Errors
        runNumber: Run number
        startTime: Start time
      recordsin:
        hint:
          title: "Number of records in: {count}"
        table:
          headers:
            inputrecords: Input records
            runCount: "Run #"
            startTime: Start time
        title: Number of records in
      recordsout:
        hint:
          title: "Number of records out: {count}"
        table:
          headers:
            inputrecords: Output records
            runCount: "Run #"
            startTime: Start time
        title: Number of records out
      xAxisTitle: "Pipeline run #"
      yAxisTitle: "Number of records"
    pipelineNodesMetricsGraph:
      checkedPortLegendsCount: "{selected} of {total} metrics displayed"
      hours: Hours
      minutes: Minutes
      nodata: No data
      numberOfRecords: Number of records
      NodeMetricsGraph:
        accumulatedRecords: Accumulated records
        numOfRecordsError: 'Number of error records'
        numOfRecordsIn: 'Number of records in'
        numOfRecordsOut: 'Number of records out'
        recordsError: 'Error records'
        recordsIn: 'Records in'
        recordsOut: 'Records out'
        ts: Timestamp
      portRecordsCountPopover:
        hide: Hide All
        title: Total records out
        view: View All
      processTimeTable:
        avgProcessTime: Average processing time
        maxProcessTime: Max process time (one record)
        minProcessTime: Min process time (one record)
        recordInPerSec: Records in per second
        recordOutPerSec: Records out per second
        stddevProcessTime: Standard deviation
      recordsErrorTitle: Errors
      recordsInTitle: Records in
      recordsOutTitle: Records out
      runOfTitle: Run {runNumber} of {totalRun}
      seconds: seconds
      totalRecordsError: "Total errors: {totalRecordsError}"
      totalRecordsIn: "Total records in: {totalRecordsIn}"
      totalRecordsOut: "Total records out: {totalRecordsOut}"
      totalRecordsOutPorts: "{port}: {recordCount}"
    runsHistoryGraph:
      hint:
        duration: Duration
        runNumber: Run number
        startTime: Start time
        status: Status
        title: Run history
      table:
        headers:
          duration: Duration
          runCount: Run#
          status: Status
          startTime: Start time
      title: Run history
      xAxisTitle: "Pipeline run #"
      yAxisTitle: Run duration ({resolution})
    runsFilter:
      last10Runs: Last 10 runs
      last50Runs: Last 50 runs
      last100Runs: Last 100 runs
      last1Day: Last 24 hours
      last7Days: Last 7 days
      last30Days: Last 30 days
      sinceInception: Since Inception
    statsContainer:
      avgRunTime: Average duration
      totalRuns: Total runs
    title: 'Summary (Max: 100 runs)'

  PipelineHistory:
    header: Version history of pipeline
    table:
      date: Date
      time: Time
      summary: Summary
      unfinish: Not yet implemented
      view: View
      restore: Restore
      rowsPerPage: "Rows per page: "
      restoreFailError: Cannot restore (deploy) selected version
      fetchVersionFailError: Cannot fetch selected version's detail
      latest: Latest version
      older: Older version
      restoreChangeSummary: "Restore version at {date}"

  PipelineTriggers:
    collapsedTabLabel: "Inbound triggers ({count})"
    description: Description
    EnabledTriggers:
      addNewTrigger: Add new trigger
      compositeTriggersPipelineCount:
        0: "No triggers set"
        1: "{context} trigger is set"
        _: "{context} triggers are set"
      compositeTriggersTitle: "View enabled triggers for pipeline \"{pipelineName}\""
      buttonLabel: Disable Trigger
      deleteTrigger: Delete Trigger
      deleteTriggerButton: Delete Trigger
      deleteConfirm: Delete
      deleteConfirmationText: "Are you sure you want to delete trigger \"{name}\"?"
      pipelineCount:
        0: "No pipelines set as trigger"
        1: "{context} pipeline is set as trigger"
        _: "{context} pipelines are set as trigger"
      tabLabel: "View enabled triggers ({count})"
      title: "View pipelines enabled to trigger pipeline \"{pipelineName}\""
    Events:
      COMPLETED: Succeeds
      FAILED: Fails
      KILLED: Stops
    expandedTabLabel: "Inbound triggers ({count})"
    helperText: "\"{pipelineName}\" is triggered when this pipeline"
    namespace: Namespace
    pipelineName: Pipeline Name
    groupTriggers: Composite Triggers
    pipelineTriggerType: "Trigger Type: {type}"
    pipelineTriggerTypeHeader: "Type"
    ScheduleRuntimeArgs:
      configure_enable_btn: Configure and Enable Trigger
      configure_select_btn: Select
      DefaultMessages:
        choose_runtime_arg: Pick runtime argument
        choose_plugin: Pick plugin
        choose_plugin_property: Pick plugin property
      PayloadConfigModal:
        configPayloadBtn: Trigger Config
        configPayloadBtnCaptalized: TRIGGER CONFIG
        configPayloadBtnDisabled: View Payload
        configPayloadBtnDisabledCapitalized: VIEW PAYLOAD
        title: Payload configuration
      Tabs:
        ComputeConfig:
          title: Select a compute profile to use when the pipeline is triggered.
          tabTitle: Compute config
        PayloadConfig:
          title: Payload config
        RuntimeArgs:
          disabledNoRuntimeArgsMessage: No runtime arguments configured for "{triggeredPipelineid}"
          noRuntimeArgsMessage: No runtime arguments found for "{triggeredPipelineid}"
          TableHeaders:
            runtimeargs: Runtime arguments to map
            t_runtimeargs: Trigger runtime arguments
          tab_message: Select how runtime arguments for trigger "{triggeringPipelineid}" map to runtime arguments for "{triggeredPipelineid}"
          tab_message2: (if not mapped, runtime arguments are derived from pipeline's or namespace's preferences)
          title: Runtime arguments
        StageProps:
          disabledNoStageConfigMessage: No plugin config configured for "{triggeredPipelineid}"
          noRuntimeArgsMessage: No runtime arguments found for "{triggeredPipelineid}"
          TableHeaders:
            pluginName: Plugin name
            pluginProperty: Plugin property
            runtimeArg: Runtime arguments to map
          tab_message: Set which of the plugin properties in trigger "{triggeringPipelineid}" map to "{triggeredPipelineid}" runtime arguments.
          tab_message2: (if not mapped, runtime arguments are derived from pipeline's or namespace's preferences)
          title: Plugin config
    SetTriggers:
      addNewTrigger: Enable the trigger
      configComputeProfie: Compute Profile
      compositeTriggersTitle: "Add a new trigger for \"{pipelineName}\""
      buttonLabel: Enable Trigger
      pipelineCount: "{count} pipelines available"
      selectedPipelines: "Selected Pipelines:"
      selectButtonLabel: Select
      tabLabel: Set pipeline triggers
      title: "Set which pipeline triggers \"{pipelineName}\""
      triggerName: "Trigger Name"
      triggerType: "Trigger Type"
      triggerNameExists: "Trigger Name already exists"
      triggerNameRequired: "Trigger Name is required"
      triggerNameLengthLimit: "Trigger Name should not be longer than 50 characters"
      selectPipelineInstruction: "Select the pipelines you want to add to the trigger: "
      triggerAndType: "Wait for all events (AND)"
      triggerOrType: "Trigger on any selected event (OR)"
      viewNamespace: View pipelines in namespace
    viewPipeline: View Pipeline
    viewPipelineCapitalized: VIEW PIPELINE
  PreviewData:
    DataView:
      Table:
        noPreviewRunning: "{recordType} records have not been generated. Please verify your logic or try sending more data."
        previewNotSupported: Preview data is not supported for condition stages.
        previewRunning: "{recordType} records have not been generated yet. Please check again in a few minutes."
      TableContainer:
        conditionHeader: Input Records and Output Records
        inputHeader: Input Records
        outputHeader: Output Records
    errorHeader: Error fetching preview data. Please try re-running preview.
    loading: Fetching preview data
    RecordView:
      RecordContainer:
        conditionHeader: Input Records and Output Records
        inputHeader: Input Records
        outputHeader: Output Records
      RecordTable:
        fieldName: Field Name
        noPreviewRunning: "{recordType} records have not been generated. Please verify your logic or try sending more data."
        noSelectedRecord: "Preview data for this stage contains fewer than {selectedRecord} records."
        previewNotSupported: Preview data is not supported for condition stages.
        previewRunning: "{recordType} records have not been generated yet. Please check again in a few minutes."
        value: Value
    runPreview: Run preview to generate preview data.
  PropertiesEditor:
    AddProperty:
      button: Add Property
      keyPlaceholder: Enter name
      modalHeader: Add property for {entityId}
      propertyExistError: Property {key} already exists
      shortError: Failed to add property
      valuePlaceholder: Enter value
    DeleteConfirmation:
      confirmationText: "Are you sure you want to delete \"{key}\" property?"
      confirmButton: Delete
      headerTitle: Delete confirmation
      shortError: Failed to delete property
    EditProperty:
      button: Save
      modalHeader: "Edit property: {key}"
      shortError: Failed to save property
      valuePlaceholder: Enter new value
    name: Name
    scope: Scope
    system: System
    user: Business
    value: Value

  Replication:
    Create:
      Content:
        SelectColumns:
          primaryKeyDescription: Must include primary key
  Reports:
    Customizer:
      clear: Clear Selection
      generate: Generate Report
      header: Select runs
      hide: Hide generate a report
      Options:
        customApps: Custom apps
        duration: Duration
        end: End time
        namespace: Namespace
        numLogErrors: "# of log errors"
        numLogWarnings: "# of log warnings"
        numRecordsOut: "# of records out"
        pipelines: Pipelines
        runtimeArgs: Runtime args
        start: Start time
        startMethod: Start method
        status: Status
        user: User
      selectColumns: Select columns
      show: Show generate a report
      StatusSelector:
        allStatuses: All statuses
        selectOne: Select one
        selectStatus: Select status
      TimeRangeSelector:
        customRange: Custom range
        label: Select time range
        labelWithColon: "Select time range: "
        last30Min: Last 30 min
        last30Minutes: Last 30 minutes
        lastHour: Last 1 hour
        select: Select time
        timeRange: "{startTime} to {endTime}"
    header: Reports
    pageTitle: '{productName} | {featureName}'
    reportName: Report name
    reports:
      1: "{context} report"
      _: "{context} reports"
    ReportsDetail:
      appTypeLabel: "App type:"
      batch: Batch pipeline
      bySchedule: By schedule
      byTrigger: By trigger
      customApp: custom app
      expiresIn: Expires in
      generatedTime: Report generated on {time}
      getReportName: "{statusLabel} runs - {startDate} to {endDate}"
      lastStarted: "Newest: {newest}; Oldest: {oldest}"
      lastStartedLabel: "Last started:"
      manually: Manually
      namespaceLabel: "Namespace:"
      numRuns: " ({num} runs)"
      ownersLabel: "Owners:"
      realtime: Realtime pipeline
      reportSummary: Report summary
      runDuration: "Min: {min}; Max: {max}; Average: {average}"
      runDurationLabel: "Run duration:"
      runs:
        1: "{context} run"
        _: "{context} runs"
      save: Save
      saved: Saved
      saveReport: Save Report
      startedLabel: "Started:"
      timeRange: "{start} to {end}"
      timeRangeLabel: "Time range:"
    ReportsList:
      cloneCriteria: Clone criteria
      created: Created
      expiration: Expiration
      failed: Failed
      generating: Generating
      makeSelection: Make a selection to specify your criteria and generate new report.
      noReports: No reports are available
      selectAReport: Select a report to view
    ReportsServiceControl:
      Benefits:
        title: "Some of the key features of {featureName} are:"
        b1: Intuitive web UI for generating, viewing and managing reports.
        b2: Support for filtering by process type (pipelines or custom apps) and status.
        b3: Historical reporting over extended time periods using Apache Spark for optimal performance.
        b4: Permanent retention for important, saved reports.
        b5: Automatic deletion of unsaved reports.
        b6: Use-case based customization of report contents (columns).
      description: "{featureName} help users generate historical analysis of programs and pipelines running in their data infrastructure. The primary goal of these reports is to help decision makers and administrators make informed business decisions about resource utilization, capacity planning, and onboarding new processes."
      enable: Enable {featureName}
      environmentCheckMessage: Checking for environment before enabling {featureName}
      errorCommunicating: Error while communicating with {featureName} service
      errorTitle: Enabling {featureName} failed
      serviceDisabledMessage: Please upgrade to Spark 2.0 or later to use {featureName}
      title: Welcome to {featureName}

  Resource-Center:
    Application:
      actionbtn0: Upload
      actionbtn-1: Create
      description: An application is a collection of datasets and programs that read and write data to datasets.
      label: Application
      modalheadertitle: Upload application
    Artifact:
      actionbtn0: Upload
      description: A driver is a JAR file that contains third-party code to communicate with systems such as MySQL, Oracle, and PostgreSQL using JDBC.
      label: Driver
      modalheadertitle: Add driver
    Directive:
      actionbtn0: Upload
      description: A directive is a data manipulation instruction that can be used to perform data cleansing, transformation and filtering.
      label: Directive
      modalheadertitle: Upload directive artifact
    HydratorPipeline:
      actionbtn0: Create
      actionbtn1: Import
      description: A pipeline allows you to create, manage, and operate complex batch and real-time workflows intuitively.
      errorLabel: "There was a problem with the pipeline you were trying to upload"
      label: Pipeline
      nonJSONError: "File should be in JSON format. Please upload a file with '.json' extension."
    Library:
      actionbtn0: Upload
      description: A library is a JAR file that can contains reusable third-party code (e.g. external Spark programs).
      label: Library
      modalheadertitle: Add library
    Microservice:
      actionbtn0: Create
      description: A reactive microservice is a decomposition of system into discrete, isolated subsystems communicating over a well defined protocol.
      label: Microservice
      modalheadertitle: Create microservice
    Plugins:
      actionbtn0: Upload
      description: A plugin is an easy way to extend the functionality of an application.
      label: Plugin
      modalheadertitle: Upload plugin artifact
  RulesEngine:
    AddRulesEngineToPipelineModal:
      batchPipelineBtn: Batch pipeline
      error: Unable to find Rules Engine Plugin. Please install Rules Engine plugin before adding to pipeline
      message: Choose the type of pipeline to create
      modalTitle: Add to pipeline
      realtimePipelineBtn: Realtime pipeline
    CreateRule:
      form:
        actionplaceholder: 'Eg. find-and-replace Name "s/ //g"'
        apply: Apply
        cancel: Cancel
        description: Description
        descriptionplaceholder: Description for the rule
        nameplaceholder: Name of the rule
        today: Today
        whenClausePlaceholder: "E.g. !isnullorempty(Name) && whitespace(Name)"
    CreateRulebook:
      admin: Admin
      createBtnLabel: Create Rulebook
      createBtnNext: "Next: Add Rules"
      created: Created
      descriptionplaceholder: Add description
      nameplaceholder: Start by naming this Rulebook
      now: Now
      owner: Owner
      version: Version {version}
    Home:
      pageTitle: '{productName} | {featureName}'
      Tabs:
        rbTitle: RuleBooks
        rulesTitle: Rules
    ImportRulebook:
      description: Upload your Rulebook file
      footertitle: Failed to upload Rulebook
      shorttitle: Import Rulebook
      title: Upload Rulebook
    Rule:
      ConfirmationModal:
        failedMessage: Deleting rule {id} failed
        text: Are you sure you want to delete "{id}"
        title: Delete Rule
    Rulebook:
      owner: Owner
      rules: Rules
    RulebookDetails:
      addone: to add one
      applyBtnLabel: Apply
      lastmodified: Modified on
      norulebooks: No Rulebooks added
      owner: Owner # ?Again should we reuse?
      version: Version {version}
    RulebookMenu:
      createPipeline: Create a pipeline
      delete: Delete
      download: Download
    RulebooksPopover:
      addToRulebookbtn: Add to RuleBook >
      norulesbooks: No Rulebooks found
    RulesEngineServiceControl:
      benefits:
        b1: "Intuitive UI: Business users can easily set up and govern data ingestion and data processing - no programming required"
        b2: "Flexible Management: Rules and Rulebooks can be easily added, updated and shared"
        b3: "Fully integrated: The {featureName} is available as a library to integrate with JBoss, WebLogic, Spring, and SQL tools"
        b4: "Scalable: The {featureName} is horizontally scalable, i.e. it scales out with your big data environment"
        b5: "Easy governance: The {featureName} provides a centralized repository for policies and transformations"
        title: "Benefits of the {featureName} include:"
      description: Business {featureName} provides an easy way to create and manage a knowledge base that is executable in your big data environment.
                  The intuitive UI allows business analysts to set up business rules and use them within a data pipeline.
      enableBtnLabel: Enable {featureName}
      errorCommunicating: Error while communicating with {featureName} service
      errorTitle: Enabling {featureName} failed
      title: Welcome to {featureName}
    RulesList:
      dropContainerText: Add a rule by dragging and dropping from the Rules tab
      rulesLabel: Rules
    RulebookRule:
      remove: Remove
    RulebooksTab:
      createrulebook: Create a new Rulebook
      importrulebook: Import a Rulebook
      searchLabel: Select a Rulebook
      searchplaceholder: Search Rulebook by name
    RulesTab:
      createRuleBtn: Create a new Rule
      date: Date
      norules: No Rules found
      searchPlaceholder: Search Rules by name, action or description
    shared:
      allFieldsRequired: "* All fields are required"
  SchemaEditor:
    Labels:
      fieldName: Field name
      symbolName: Symbol name
  ServiceEnableUtility:
    serviceNotFound: Cannot find {artifactName} artifact
  SpotlightSearch:
    SpotlightModal:
      headerTagResults: Entities with the tag "{tag}"
      noResults: There are no entities with the tag "{tag}"
      numResult: "{total} result"
      numResults: "{total} results"

  StatusAlertMessage:
    message: 'Services are back online'
  Tags:
    allTags: All Tags
    labelWithCount: Tags ({count})
    notags: No tags found. Click to add a new business tag.

  TriggeredPipelines:
    collapsedTabLabel: "Outbound triggers ({count})"
    description: Description
    Events:
      COMPLETED: Succeeds
      KILLED: Stopped
      FAILED: Fails
    expandedTabLabel: "Outbound triggers ({count})"
    helperText: "This pipeline is triggered when \"{pipelineName}\""
    compositeTriggerHelperText: "This pipeline is triggered when \"{pipelineName}\" of composite trigger \"{triggerName}\""
    namespace: Namespace
    pipelineCount:
      "0": "No pipelines triggered"
      "1": "1 pipeline triggered"
      _: "{context.count} pipelines triggered"
    pipelineName: Pipeline name
    title: "Pipelines to be triggered by \"{pipelineName}\""
    viewPipeline: View Pipeline
    viewPipelineCapitalized: VIEW PIPELINE

  ViewAllLabel:
    viewAll: View all
    viewLess: View less

  ViewSwitch:
    actionsLabel: Actions
    DatasetTable:
      readsLabel: Reads
      writesLabel: Writes
      eventsLabel: Events
      sizeLabel: Size
    nameLabel: Name
    ProgramTable:
      lastStartedLabel: Last started
      statusLabel: Status
    typeLabel: Type
  WarningContainer:
    title: Warning
  Wizard:
    Add-Namespace:
      callToAction:
        primary: Switch to '{namespaceId}'
      headerlabel: Add namespace
      Status:
        creation-error-desc: "Failed to create the namespace '%s'."
        creation-success-desc: Successfully created the namespace '{namespaceId}'.
      GeneralInfoStep:
        description-label: "Description"
        description-placeholder: "Namespace description"
        name-label: "Name"
        name-placeholder: "Namespace name"
        scheduler-queue-label: "Scheduler queue"
        sld-desc:  "Specify the name and the description of the namespace."
        ssd-label: "General information"
      ResourcesStep:
        k8s-nm-name-label: "Kubernetes namespace name"
        k8s-nm-name-placeholder: "Kubernetes namespace where jobs in this namespace will run"
        k8s-nm-cpu-limit-label: "Kubernetes namespace cpu limit"
        k8s-nm-cpu-limit-placeholder: "CPU limit in this namespace (in number of cores)"
        k8s-nm-memory-limit-label: "Kubernetes namespace memory limit"
        k8s-nm-memory-limit-placeholder: "Memory limit in this namespace (in GB)"
        service-account-email-label: "GCP Service Account Email"
        service-account-email-placeholder: "GCP service account to use when running workloads in this namespace"
        sld-label: "Specify the resources that jobs in this namespace will use."
        ssd-label: "Resources"
      PreferencesStep:
        name-label: "Name"
        name-placeholder: "Preference name"
        sld-label: "Specify preferences to be applied at the namespace level."
        ssd-label: "Preferences"
        value-label: "Value"
        value-placeholder: "Preference value"
      HadoopMappingStep:
        hbase-nm-name-label: "HBase namespace name"
        hbase-nm-name-placeholder: "Namespace in HBase for datasets in this namespace"
        hdfs-root-directory-label: "HDFS root directory"
        hdfs-root-directory-placeholder: "Base directory on HDFS for this namespace"
        hive-db-name-label: "Hive database name"
        hive-db-name-placeholder: "Hive database for this namespace"
        scheduler-queue-name: "Scheduler queue name"
        scheduler-queue-placeholder: "Yarn queue name to be used to submit programs in this namespace"
        sld-label: "Specify mapping of namespace resources to underlying Hadoop resources (Only used when deployed on Apache Hadoop)."
        ssd-label: "Hadoop mapping"
      SecurityStep:
        keytab-uri-label: "Keytab URI"
        keytab-uri-placeholder: "Location of keytab file associated with the principal"
        principal-label: "Principal"
        principal-placeholder: "Kerberos principal of the user to run programs as"
        sld-label: "Specify credentials for securely impersonating programs in this namespace."
        ssd-label: "Security"
    ApplicationUpload:
      headerlabel: Upload application
      Step1:
        description: Upload your application JAR file.
        filePathLabel: Choose file
        shorttitle: Upload application
        title: Upload JAR file
        uploadHelperText: Upload the JAR file for the application that you wish to deploy
      success: You have successfully deployed the application "{appName}".
    ArtifactUpload:
      callToAction: Create a Pipeline
      headerlabel: Add third party driver
      footertitle: Add driver
      Step1:
        description: Upload your driver.
        filePathLabel: Choose file
        shorttitle: Upload driver
        title: Upload JAR file
        uploadHelperText: Upload the third party driver that was downloaded in the previous step
      Step2:
        classnameLabel: Class name
        classnamePlaceholder: Driver class name. E.g. com.example.MyClass
        description: Configure the settings for your driver.
        descriptionLabel: Description
        descriptionPlaceholder: Driver description
        nameLabel: Name
        namePlaceholder: Driver name
        parentArtifactLabel: Parent artifact
        shorttitle: Driver configuration
        title: Configure driver
        versionLabel: Version
        versionPlaceholder: Driver version
      success: You have successfully uploaded the driver "{artifactName}".
      subtitle: You can now create a pipeline to extract data from database using the driver.
    DirectiveUpload:
      callToAction: Go to Wrangler
      footertitle: Upload directive artifact
      Step1:
        description: Upload your directive JAR file.
        errorMessage: Invalid directive. Directive must be a JAR file.
        filePathLabel: Choose file
        shorttitle: Upload directive JAR file
        title: Upload directive JAR file
      Step2:
        description: Upload the directive configuration JSON file.
        errorMessage: Invalid directive JSON. Plugin configuration should be in JSON format.
        errorMessageParentArtifacts: Invalid directive JSON. Please specify parent artifacts.
        shorttitle: Upload directive configuration JSON file
        title: Upload directive configuration JSON file
      subtitle: Start preparing data with the directive.
      success: You have successfully uploaded the directive "{pluginName}".
    Done: Done
    FailedMessage: Failed to {step}
    GoToHomePage: Go to homepage
    Informational:
      headerlabel: Download information
      Step1:
        description: Please follow the steps specified below to download and configure
        shorttitle: Download information
        title: Information
    LibraryUpload:
      callToAction: Create a Pipeline
      headerlabel: Add library
      footertitle: Add library
      Step1:
        description: Upload your library.
        shorttitle: Upload library
        title: Upload JAR file
        filePathLabel: Choose file
      Step2:
        classnameLabel: Class name
        classnamePlaceholder: com.example.MyClass
        description: Configure the settings for your library.
        descriptionLabel: Description
        descriptionPlaceholder: Library description
        nameLabel: Name
        namePlaceholder: Library name
        parentArtifactLabel: Parent artifact
        shorttitle: Library configuration
        title: Configure library
        typeLabel: Type
        typePlaceholder: Library type. E.g. sparkprogram
        versionLabel: Version
        versionPlaceholder: Library version
      success: You have successfully uploaded the library "{artifactName}".
      subtitle: You can now create a pipeline using the library.
    licenseStep:
      agreeAndActionBtnLabel: Agree
      backToCaskBtnLabel: Back to Hub
      termsandconditions: Terms and Conditions
    MarketHydratorPluginUpload:
      headerlabel: Add Hydrator plugin
    MicroserviceUpload:
      callToAction: Start Microservice
      headerlabel: Add microservice
      footertitle: Add microservice
      MicroserviceQueue:
        labels:
          accessId: Access-id
          accessKey: Access-key
          connection: Connection string
          endpoint: Endpoint
          keySerdes: Key serdes
          mapRTopic: Topic name
          namespace: Namespace
          queueName: Queue name
          region: Region
          sslKeystoreFilePath: SSL keystore file path
          sslKeystoreKeyPassword: SSL keystore key password
          sslKeystorePassword: SSL keystore password
          sslKeystoreType: SSL keystore type
          sslTruststoreFilePath: SSL truststore file path
          sslTruststorePassword: SSL truststore password
          sslTruststoreType: SSL truststore type
          topic: Topic name
          valueSerdes: Value serdes
        types:
          mapr-stream: Mapr Stream
          sqs: Amazon SQS
          tms: TMS (Transactional Messaging System)
          websocket: Websocket
      secondaryCallToAction: Microservice Details
      Step1:
        description: Provide name, description and version for a microservice you would like to create.
        descriptionPlaceholder: Description of the microservice
        helperText: Microservice Core is not available. Please contact support@cask.co to enable.
        instanceNameLabel: Instance name
        instanceNamePlaceholder: Name of the microservice instance
        microserviceOptionLabel: Microservice name
        microserviceOptionPlaceholder: Name of the microservice
        newMicroservicePlaceholder: Name of the new microservice
        shorttitle: General
        summary: "Creates an instance of microservice '{microserviceName}' with name '{instanceName}' and version {version}."
        title: General
        versionLabel: Version
        versionPlaceholder: Version of the microservice
      Step2:
        description: An Artifact containing implementation of the microservice interface.
        errorMessage: Invalid plugin. Plugin must be a JAR file.
        filePathLabel: Choose file
        shorttitle: Artifact JAR file
        title: Artifact JAR file
      Step3:
        description: A configuration for this microservice artifact.
        errorMessage: Invalid microservice JSON. Microservice configuration should be in JSON format.
        errorMessageParentArtifacts: Invalid microservice JSON. Please specify parent artifacts.
        filePathLabel: Choose file
        shorttitle: Artifact JSON file
        title: Artifact JSON file
      Step4:
        description: Specify resources for the runtime of this microservice.
        instancesLabel: Instances
        instancesPlaceholder: The number of instances of the microservice
        memoryLabel: Memory
        memoryPlaceholder: The memory in MB for the microservice
        shorttitle: Resources
        summary:
          count:
            instances:
              1: '{context} instance'
              _: '{context} instances'
            vcores:
              1: '{context} core'
              _: '{context} cores'
            memory:
              1: '{context} MB'
              _: '{context} MBs'
            ethreshold:
              1: '{context} error'
              _: '{context} errors'
          text: "{instancesWithCount} of microservice '{instanceName}' will be started using {vcoresWithCount}, {memoryWithCount} of memory and with error threshold on event processing as {ethresholdWithCount}."
        thresholdLabel: Threshold
        thresholdPlaceholder: TBD
        title: Resources
        vcoresLabel: Virtual cores
        vcoresPlaceholder: The number of virtual cores for the microservice
      Step5:
        description: Provide inbound queue properties.
        fetchLabel: Fetch size
        propertiesLabel: Inbound queues
        shorttitle: Inbound queues
        title: Inbound queues
      Step6:
        description: Provide outbound queue properties.
        propertiesLabel: Outbound queues
        shorttitle: Outbound queues
        title: Outbound queues
      Step7:
        description: Provide microservice specific properties.
        keyPlaceholder: name
        propertiesLabel: Properties
        shorttitle: Properties
        title: Properties
      success: You have successfully created the microservice "{appName}".
      summaryLabel: "Summary: "
    NavigationButtons:
      finish: Finish
      next: Next
      previous: Previous
    OneStepDeploy:
      headerlabel: Deploy
      Step1:
        description: Deploy {entityType} using JAR file.
        shorttitle: Deploy {entityType}
        title: Deploy JAR file
    PluginArtifact:
      callToAction: Create a pipeline
      footertitle: Upload plugin artifact
      Step1:
        description: Upload your plugin JAR file.
        errorMessage: Invalid plugin. Plugin must be a JAR file.
        filePathLabel: Choose File
        shorttitle: Upload plugin JAR file
        title: Upload plugin JAR file
      Step2:
        description: Upload the plugin configuration JSON file.
        errorMessage: Invalid plugin JSON. Plugin configuration should be in JSON format.
        errorMessageParentArtifacts: Invalid plugin JSON. Please specify parent artifacts.
        shorttitle: Upload plugin configuration JSON file
        title: Upload plugin configuration JSON file
      subtitle: Start creating a pipeline with the plugin.
      success: You have successfully uploaded the plugin "{pluginName}".
    PublishPipeline:
      callToAction:
        customize: Customize Pipeline
        view: View Pipeline
      headerlabel: Deploy pipeline
      pipelinenameplaceholder: Pipeline name
      Step1:
        description: Specify the name of the pipeline.
        shorttitle: Configure pipeline
        title: Configure a pipeline
      success: You have successfully created the pipeline "{pipelineName}".
    Skip: Skipped
...
